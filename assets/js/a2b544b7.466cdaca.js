"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[9736],{2642:(n,e,a)=>{a.r(e),a.d(e,{assets:()=>l,contentTitle:()=>r,default:()=>c,frontMatter:()=>s,metadata:()=>t,toc:()=>p});const t=JSON.parse('{"id":"module-3-ai-robot-brain/navigation/nav2-bipedal-navigation","title":"Nav2: Bipedal Path Planning for Humanoid Robots","description":"Overview","source":"@site/docs/module-3-ai-robot-brain/navigation/nav2-bipedal-navigation.md","sourceDirName":"module-3-ai-robot-brain/navigation","slug":"/module-3-ai-robot-brain/navigation/nav2-bipedal-navigation","permalink":"/hackathon_textbook_ai_robotics/docs/module-3-ai-robot-brain/navigation/nav2-bipedal-navigation","draft":false,"unlisted":false,"editUrl":"https://github.com/Jiyakhan321/hackathon_textbook_ai_robotics/tree/main/docs/module-3-ai-robot-brain/navigation/nav2-bipedal-navigation.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6},"sidebar":"tutorialSidebar","previous":{"title":"Isaac ROS: Hardware-Accelerated Perception","permalink":"/hackathon_textbook_ai_robotics/docs/module-3-ai-robot-brain/ai-integration/isaac-ros-perception"},"next":{"title":"VSLAM Implementation for Humanoid Robots","permalink":"/hackathon_textbook_ai_robotics/docs/module-3-ai-robot-brain/practical-exercises/vslam-implementation"}}');var o=a(4848),i=a(8453);const s={sidebar_position:6},r="Nav2: Bipedal Path Planning for Humanoid Robots",l={},p=[{value:"Overview",id:"overview",level:2},{value:"Nav2 Architecture for Humanoids",id:"nav2-architecture-for-humanoids",level:2},{value:"1. System Architecture Overview",id:"1-system-architecture-overview",level:3},{value:"2. Humanoid-Specific Challenges",id:"2-humanoid-specific-challenges",level:3},{value:"Nav2 Installation and Basic Setup",id:"nav2-installation-and-basic-setup",level:2},{value:"1. Installing Nav2 for Humanoid Applications",id:"1-installing-nav2-for-humanoid-applications",level:3},{value:"2. Basic Nav2 Configuration",id:"2-basic-nav2-configuration",level:3},{value:"Humanoid-Specific Path Planning",id:"humanoid-specific-path-planning",level:2},{value:"1. Footstep Planning Integration",id:"1-footstep-planning-integration",level:3},{value:"2. Balance-Aware Path Planning",id:"2-balance-aware-path-planning",level:3},{value:"Stair and Multi-Floor Navigation",id:"stair-and-multi-floor-navigation",level:2},{value:"1. Stair Navigation Planning",id:"1-stair-navigation-planning",level:3},{value:"Humanoid Navigation Controller",id:"humanoid-navigation-controller",level:2},{value:"1. Walking Controller Integration",id:"1-walking-controller-integration",level:3},{value:"Complete Navigation Launch Files",id:"complete-navigation-launch-files",level:2},{value:"1. Humanoid Navigation Launch",id:"1-humanoid-navigation-launch",level:3},{value:"Next Steps",id:"next-steps",level:2}];function _(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"nav2-bipedal-path-planning-for-humanoid-robots",children:"Nav2: Bipedal Path Planning for Humanoid Robots"})}),"\n",(0,o.jsx)(e.h2,{id:"overview",children:"Overview"}),"\n",(0,o.jsx)(e.p,{children:"Navigation 2 (Nav2) is the state-of-the-art navigation framework for ROS 2, but it requires significant adaptation for humanoid robots with bipedal locomotion. This section covers configuring Nav2 specifically for humanoid robots, including footstep planning, balance-aware path planning, and multi-floor navigation that accounts for the unique challenges of walking robots."}),"\n",(0,o.jsx)(e.p,{children:"Unlike wheeled robots, humanoid robots must consider balance, foot placement, and dynamic stability during navigation, making traditional path planning approaches insufficient for safe and stable locomotion."}),"\n",(0,o.jsx)(e.h2,{id:"nav2-architecture-for-humanoids",children:"Nav2 Architecture for Humanoids"}),"\n",(0,o.jsx)(e.h3,{id:"1-system-architecture-overview",children:"1. System Architecture Overview"}),"\n",(0,o.jsx)(e.p,{children:"The Nav2 system for humanoid robots includes specialized components:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                 HUMANOID NAV2 ARCHITECTURE                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502  \u2502   PLANNING  \u2502    \u2502  FOOTSTEP   \u2502    \u2502  CONTROLLER \u2502     \u2502\n\u2502  \u2502             \u2502\u2500\u2500\u2500\u25b6\u2502             \u2502\u2500\u2500\u2500\u25b6\u2502             \u2502     \u2502\n\u2502  \u2502 \u2022 Global    \u2502    \u2502 \u2022 Footstep  \u2502    \u2502 \u2022 Balance   \u2502     \u2502\n\u2502  \u2502   Planner   \u2502    \u2502   Planning  \u2502    \u2502   Control   \u2502     \u2502\n\u2502  \u2502 \u2022 Local     \u2502    \u2502 \u2022 Stability \u2502    \u2502 \u2022 Walking   \u2502     \u2502\n\u2502  \u2502   Planner   \u2502    \u2502   Checks    \u2502    \u2502   Control   \u2502     \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,o.jsx)(e.h3,{id:"2-humanoid-specific-challenges",children:"2. Humanoid-Specific Challenges"}),"\n",(0,o.jsx)(e.p,{children:"Humanoid navigation presents unique challenges:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Balance Constraints"}),": Paths must maintain robot stability"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Footstep Planning"}),": Each step must be carefully planned"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Dynamic Locomotion"}),": Walking motion affects localization"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Stair Navigation"}),": Multi-floor capability required"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Terrain Adaptation"}),": Different surfaces require different gaits"]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"nav2-installation-and-basic-setup",children:"Nav2 Installation and Basic Setup"}),"\n",(0,o.jsx)(e.h3,{id:"1-installing-nav2-for-humanoid-applications",children:"1. Installing Nav2 for Humanoid Applications"}),"\n",(0,o.jsx)(e.p,{children:"Setting up Nav2 with humanoid-specific packages:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-bash",children:"# Install Nav2 base packages\nsudo apt update\nsudo apt install -y ros-humble-navigation2\nsudo apt install -y ros-humble-nav2-bringup\nsudo apt install -y ros-humble-nav2-gui\n\n# Install additional packages for humanoid navigation\nsudo apt install -y ros-humble-nav2-rviz-plugins\nsudo apt install -y ros-humble-robot-localization\nsudo apt install -y ros-humble-interactive-markers\n\n# Install humanoid-specific packages (if available)\n# For custom implementations, we'll create our own packages\n"})}),"\n",(0,o.jsx)(e.h3,{id:"2-basic-nav2-configuration",children:"2. Basic Nav2 Configuration"}),"\n",(0,o.jsx)(e.p,{children:"Creating a basic Nav2 configuration for humanoid robots:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-yaml",children:'# config/humanoid_nav2_params.yaml\namcl:\n  ros__parameters:\n    use_sim_time: True\n    alpha1: 0.2\n    alpha2: 0.2\n    alpha3: 0.2\n    alpha4: 0.2\n    alpha5: 0.2\n    base_frame_id: "base_link"\n    beam_skip_distance: 0.5\n    beam_skip_error_threshold: 0.9\n    beam_skip_threshold: 0.3\n    do_beamskip: false\n    global_frame_id: "map"\n    lambda_short: 0.1\n    laser_likelihood_max_dist: 2.0\n    laser_max_range: 100.0\n    laser_min_range: -1.0\n    laser_model_type: "likelihood_field"\n    max_beams: 60\n    max_particles: 2000\n    min_particles: 500\n    odom_frame_id: "odom"\n    pf_err: 0.05\n    pf_z: 0.99\n    recovery_alpha_fast: 0.0\n    recovery_alpha_slow: 0.0\n    resample_interval: 1\n    robot_model_type: "nav2_amcl::DifferentialMotionModel"\n    save_pose_rate: 0.5\n    sigma_hit: 0.2\n    tf_broadcast: true\n    transform_tolerance: 1.0\n    update_min_a: 0.2\n    update_min_d: 0.2\n    z_hit: 0.5\n    z_max: 0.05\n    z_rand: 0.5\n    z_short: 0.05\n\namcl_map_client:\n  ros__parameters:\n    use_sim_time: True\n\namcl_rclcpp_node:\n  ros__parameters:\n    use_sim_time: True\n\nbt_navigator:\n  ros__parameters:\n    use_sim_time: True\n    global_frame: "map"\n    robot_base_frame: "base_link"\n    odom_topic: "/odom"\n    bt_loop_duration: 10\n    default_server_timeout: 20\n    # Humanoid-specific behavior tree\n    # We\'ll define this in the next section\n    plugin_lib_names:\n    - nav2_compute_path_to_pose_action_bt_node\n    - nav2_follow_path_action_bt_node\n    - nav2_back_up_action_bt_node\n    - nav2_spin_action_bt_node\n    - nav2_wait_action_bt_node\n    - nav2_clear_costmap_service_bt_node\n    - nav2_is_stuck_condition_bt_node\n    - nav2_goal_reached_condition_bt_node\n    - nav2_goal_updated_condition_bt_node\n    - nav2_initial_pose_received_condition_bt_node\n    - nav2_reinitialize_global_localization_service_bt_node\n    - nav2_rate_controller_bt_node\n    - nav2_distance_controller_bt_node\n    - nav2_speed_controller_bt_node\n    - nav2_truncate_path_action_bt_node\n    - nav2_goal_updater_node_bt_node\n    - nav2_recovery_node_bt_node\n    - nav2_pipeline_sequence_bt_node\n    - nav2_round_robin_node_bt_node\n    - nav2_transform_available_condition_bt_node\n    - nav2_time_expired_condition_bt_node\n    - nav2_path_expiring_timer_condition\n    - nav2_distance_traveled_condition_bt_node\n    - nav2_single_trigger_bt_node\n    - nav2_is_battery_low_condition_bt_node\n    - nav2_navigate_through_poses_action_bt_node\n    - nav2_navigate_to_pose_action_bt_node\n    - nav2_remove_passed_goals_action_bt_node\n    - nav2_planner_selector_bt_node\n    - nav2_controller_selector_bt_node\n    - nav2_goal_checker_selector_bt_node\n    - nav2_controller_cancel_bt_node\n    - nav2_path_longer_on_approach_bt_node\n    - nav2_wait_cancel_bt_node\n\nbt_navigator_rclcpp_node:\n  ros__parameters:\n    use_sim_time: True\n\ncontroller_server:\n  ros__parameters:\n    use_sim_time: True\n    controller_frequency: 20.0\n    min_x_velocity_threshold: 0.001\n    min_y_velocity_threshold: 0.5\n    min_theta_velocity_threshold: 0.001\n    # Humanoid-specific controllers\n    progress_checker_plugin: "progress_checker"\n    goal_checker_plugin: "goal_checker"\n    controller_plugins: ["FollowPath"]\n\n    # Humanoid bipedal controller\n    FollowPath:\n      plugin: "nav2_mppi_controller::MPPIController"\n      time_steps: 50\n      model_dt: 0.05\n      batch_size: 1000\n      vx_std: 0.2\n      vy_std: 0.0\n      wz_std: 0.3\n      vx_max: 0.5\n      vx_min: -0.1\n      vy_max: 1.0\n      wz_max: 1.5\n      xy_goal_tolerance: 0.25\n      yaw_goal_tolerance: 0.25\n      state_reset_tolerance: 0.5\n      control_horizon: 10\n      trajectory_visualization_enabled: true\n      # Humanoid-specific parameters\n      balance_weight: 10.0\n      step_size: 0.3  # Typical humanoid step size\n      max_step_height: 0.15  # Maximum step height (15cm)\n\n    progress_checker:\n      plugin: "nav2_controller::SimpleProgressChecker"\n      required_movement_radius: 0.5\n      movement_time_allowance: 10.0\n\n    goal_checker:\n      plugin: "nav2_controller::SimpleGoalChecker"\n      xy_goal_tolerance: 0.25\n      yaw_goal_tolerance: 0.25\n      state_tolerance: 0.05\n\nlocal_costmap:\n  local_costmap:\n    ros__parameters:\n      update_frequency: 5.0\n      publish_frequency: 2.0\n      global_frame: "odom"\n      robot_base_frame: "base_link"\n      use_sim_time: True\n      rolling_window: true\n      width: 6\n      height: 6\n      resolution: 0.05\n      robot_radius: 0.4  # Humanoid robot radius\n      plugins: ["voxel_layer", "inflation_layer"]\n      inflation_layer:\n        plugin: "nav2_costmap_2d::InflationLayer"\n        cost_scaling_factor: 3.0\n        inflation_radius: 0.55\n      voxel_layer:\n        plugin: "nav2_costmap_2d::VoxelLayer"\n        enabled: True\n        publish_voxel_map: True\n        origin_z: 0.0\n        z_resolution: 0.2\n        z_voxels: 8\n        max_obstacle_height: 2.0\n        mark_threshold: 0\n        observation_sources: scan\n        scan:\n          topic: "/scan"\n          max_obstacle_height: 2.0\n          clearing: True\n          marking: True\n          data_type: "LaserScan"\n          raytrace_max_range: 3.0\n          raytrace_min_range: 0.0\n          obstacle_max_range: 2.5\n          obstacle_min_range: 0.0\n      static_layer:\n        plugin: "nav2_costmap_2d::StaticLayer"\n        map_subscribe_transient_local: True\n      always_send_full_costmap: True\n\nglobal_costmap:\n  global_costmap:\n    ros__parameters:\n      update_frequency: 1.0\n      publish_frequency: 1.0\n      global_frame: "map"\n      robot_base_frame: "base_link"\n      use_sim_time: True\n      robot_radius: 0.4\n      resolution: 0.05\n      track_unknown_space: true\n      plugins: ["static_layer", "obstacle_layer", "inflation_layer"]\n      obstacle_layer:\n        plugin: "nav2_costmap_2d::VoxelLayer"\n        enabled: True\n        publish_voxel_map: True\n        origin_z: 0.0\n        z_resolution: 0.2\n        z_voxels: 8\n        max_obstacle_height: 2.0\n        mark_threshold: 0\n        observation_sources: scan\n        scan:\n          topic: "/scan"\n          max_obstacle_height: 2.0\n          clearing: True\n          marking: True\n          data_type: "LaserScan"\n          raytrace_max_range: 3.0\n          raytrace_min_range: 0.0\n          obstacle_max_range: 2.5\n          obstacle_min_range: 0.0\n      static_layer:\n        plugin: "nav2_costmap_2d::StaticLayer"\n        map_subscribe_transient_local: True\n      inflation_layer:\n        plugin: "nav2_costmap_2d::InflationLayer"\n        cost_scaling_factor: 3.0\n        inflation_radius: 0.55\n\nplanner_server:\n  ros__parameters:\n    expected_planner_frequency: 20.0\n    use_sim_time: True\n    planner_plugins: ["GridBased"]\n    GridBased:\n      # For humanoid robots, we\'ll use a custom planner\n      # that considers balance and footstep constraints\n      plugin: "nav2_navfn_planner::NavfnPlanner"\n      tolerance: 0.5\n      use_astar: false\n      allow_unknown: true\n'})}),"\n",(0,o.jsx)(e.h2,{id:"humanoid-specific-path-planning",children:"Humanoid-Specific Path Planning"}),"\n",(0,o.jsx)(e.h3,{id:"1-footstep-planning-integration",children:"1. Footstep Planning Integration"}),"\n",(0,o.jsx)(e.p,{children:"Creating a custom footstep planner for humanoid navigation:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\n# footstep_planner.py\n\nimport rclpy\nfrom rclpy.node import Node\nfrom nav_msgs.msg import Path, OccupancyGrid\nfrom geometry_msgs.msg import PoseStamped, Point\nfrom visualization_msgs.msg import Marker, MarkerArray\nfrom builtin_interfaces.msg import Duration\nfrom std_msgs.msg import Header\nimport numpy as np\nimport math\n\nclass FootstepPlanner(Node):\n    """\n    Footstep planner for humanoid robot navigation\n    """\n    def __init__(self):\n        super().__init__(\'footstep_planner\')\n\n        # Create subscribers\n        self.path_sub = self.create_subscription(\n            Path,\n            \'/plan\',\n            self.path_callback,\n            10\n        )\n\n        self.costmap_sub = self.create_subscription(\n            OccupancyGrid,\n            \'/global_costmap/costmap\',\n            self.costmap_callback,\n            10\n        )\n\n        # Create publishers\n        self.footstep_path_pub = self.create_publisher(\n            Path,\n            \'/footstep_plan\',\n            10\n        )\n\n        self.footstep_viz_pub = self.create_publisher(\n            MarkerArray,\n            \'/footsteps_visualization\',\n            10\n        )\n\n        # Initialize variables\n        self.costmap = None\n        self.resolution = 0.05\n        self.origin = None\n        self.width = 0\n        self.height = 0\n\n        # Footstep parameters\n        self.step_size = 0.3  # 30cm step\n        self.step_width = 0.2  # 20cm foot width\n        self.max_step_height = 0.15  # 15cm max step height\n        self.balance_margin = 0.1  # 10cm balance margin\n\n        # Visualization markers\n        self.footstep_markers = MarkerArray()\n\n        self.get_logger().info(\'Footstep Planner initialized\')\n\n    def costmap_callback(self, msg):\n        """\n        Store costmap information\n        """\n        self.costmap = np.array(msg.data).reshape(msg.info.height, msg.info.width)\n        self.resolution = msg.info.resolution\n        self.origin = (msg.info.origin.position.x, msg.info.origin.position.y)\n        self.width = msg.info.width\n        self.height = msg.info.height\n\n    def path_callback(self, msg):\n        """\n        Process incoming path and generate footstep plan\n        """\n        if self.costmap is None:\n            self.get_logger().warn(\'Costmap not received yet\')\n            return\n\n        # Convert path to footstep plan\n        footstep_path = self.generate_footsteps(msg)\n\n        # Publish footstep path\n        self.footstep_path_pub.publish(footstep_path)\n\n        # Publish visualization\n        self.publish_footstep_visualization(footstep_path)\n\n    def generate_footsteps(self, global_path):\n        """\n        Generate footstep plan from global path\n        """\n        footstep_path = Path()\n        footstep_path.header = global_path.header\n\n        if len(global_path.poses) < 2:\n            return footstep_path\n\n        # Start with left foot\n        current_foot = "left"\n        current_pos = np.array([global_path.poses[0].pose.position.x,\n                               global_path.poses[0].pose.position.y])\n\n        footsteps = [current_pos.copy()]\n\n        # Process path in segments\n        for i in range(1, len(global_path.poses)):\n            target_pos = np.array([global_path.poses[i].pose.position.x,\n                                  global_path.poses[i].pose.position.y])\n\n            # Calculate direction and distance\n            direction = target_pos - current_pos\n            distance = np.linalg.norm(direction)\n\n            if distance > self.step_size:\n                # Calculate number of steps needed\n                num_steps = int(distance / self.step_size)\n                step_vector = direction / distance * self.step_size\n\n                # Generate intermediate footsteps\n                for j in range(num_steps):\n                    next_pos = current_pos + step_vector\n                    if self.is_valid_footstep(next_pos):\n                        footsteps.append(next_pos.copy())\n                        current_pos = next_pos\n                        # Alternate feet\n                        current_foot = "right" if current_foot == "left" else "left"\n                    else:\n                        # Find alternative path if step is invalid\n                        alternative_pos = self.find_alternative_footstep(current_pos, target_pos)\n                        if alternative_pos is not None:\n                            footsteps.append(alternative_pos.copy())\n                            current_pos = alternative_pos\n                            current_foot = "right" if current_foot == "left" else "left"\n                        else:\n                            self.get_logger().warn(f\'Could not find valid footstep near {next_pos}\')\n                            break\n\n        # Convert to Path message\n        for i, pos in enumerate(footsteps):\n            pose_stamped = PoseStamped()\n            pose_stamped.header = global_path.header\n            pose_stamped.pose.position.x = float(pos[0])\n            pose_stamped.pose.position.y = float(pos[1])\n            pose_stamped.pose.position.z = 0.0\n\n            # Add orientation (facing direction of next step)\n            if i < len(footsteps) - 1:\n                next_pos = footsteps[i + 1]\n                yaw = math.atan2(next_pos[1] - pos[1], next_pos[0] - pos[0])\n                # Convert to quaternion\n                pose_stamped.pose.orientation.z = math.sin(yaw / 2)\n                pose_stamped.pose.orientation.w = math.cos(yaw / 2)\n\n            footstep_path.poses.append(pose_stamped)\n\n        return footstep_path\n\n    def is_valid_footstep(self, position):\n        """\n        Check if a footstep is valid (not on obstacles, within bounds)\n        """\n        if self.costmap is None:\n            return False\n\n        # Convert world coordinates to costmap indices\n        map_x = int((position[0] - self.origin[0]) / self.resolution)\n        map_y = int((position[1] - self.origin[1]) / self.resolution)\n\n        # Check bounds\n        if map_x < 0 or map_x >= self.width or map_y < 0 or map_y >= self.height:\n            return False\n\n        # Check cost (should be free space)\n        cost = self.costmap[map_y, map_x]\n        if cost >= 50:  # Threshold for obstacle\n            return False\n\n        # Check surrounding area for balance (3x3 area around foot)\n        for dx in range(-1, 2):\n            for dy in range(-1, 2):\n                check_x, check_y = map_x + dx, map_y + dy\n                if (0 <= check_x < self.width and 0 <= check_y < self.height):\n                    if self.costmap[check_y, check_x] >= 75:  # Higher threshold for immediate area\n                        return False\n\n        return True\n\n    def find_alternative_footstep(self, current_pos, target_pos):\n        """\n        Find alternative footstep if primary location is invalid\n        """\n        # Try circular search around current position\n        search_radius = self.step_size * 1.5\n        step_angle = 0.2  # 0.2 radian steps (~11 degrees)\n\n        for radius in np.arange(0.1, search_radius, 0.1):\n            for angle in np.arange(0, 2 * math.pi, step_angle):\n                alt_x = current_pos[0] + radius * math.cos(angle)\n                alt_y = current_pos[1] + radius * math.sin(angle)\n                alt_pos = np.array([alt_x, alt_y])\n\n                # Check if this alternative is closer to target and valid\n                if (np.linalg.norm(alt_pos - target_pos) < np.linalg.norm(current_pos - target_pos) and\n                    self.is_valid_footstep(alt_pos)):\n                    return alt_pos\n\n        return None\n\n    def publish_footstep_visualization(self, footstep_path):\n        """\n        Publish visualization markers for footsteps\n        """\n        marker_array = MarkerArray()\n\n        for i, pose_stamped in enumerate(footstep_path.poses):\n            # Create foot marker\n            foot_marker = Marker()\n            foot_marker.header = footstep_path.header\n            foot_marker.ns = "footsteps"\n            foot_marker.id = i\n            foot_marker.type = Marker.CUBE\n            foot_marker.action = Marker.ADD\n\n            foot_marker.pose = pose_stamped.pose\n            foot_marker.pose.position.z = 0.02  # Slightly above ground\n\n            # Different colors for left/right feet\n            if i % 2 == 0:  # Left foot\n                foot_marker.color.r = 1.0\n                foot_marker.color.g = 0.0\n                foot_marker.color.b = 0.0\n            else:  # Right foot\n                foot_marker.color.r = 0.0\n                foot_marker.color.g = 0.0\n                foot_marker.color.b = 1.0\n            foot_marker.color.a = 0.8\n\n            foot_marker.scale.x = self.step_size * 0.8  # Foot length\n            foot_marker.scale.y = self.step_width  # Foot width\n            foot_marker.scale.z = 0.01  # Thickness\n\n            marker_array.markers.append(foot_marker)\n\n        self.footstep_viz_pub.publish(marker_array)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    footstep_planner = FootstepPlanner()\n\n    try:\n        rclpy.spin(footstep_planner)\n    except KeyboardInterrupt:\n        footstep_planner.get_logger().info(\'Shutting down footstep planner\')\n    finally:\n        footstep_planner.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,o.jsx)(e.h3,{id:"2-balance-aware-path-planning",children:"2. Balance-Aware Path Planning"}),"\n",(0,o.jsx)(e.p,{children:"Implementing balance-aware navigation planning:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\n# balance_aware_planner.py\n\nimport rclpy\nfrom rclpy.node import Node\nfrom nav_msgs.msg import Path, OccupancyGrid\nfrom geometry_msgs.msg import PoseStamped, Point, PolygonStamped\nfrom visualization_msgs.msg import Marker, MarkerArray\nfrom sensor_msgs.msg import LaserScan\nfrom std_msgs.msg import Float64\nimport numpy as np\nimport math\nfrom scipy.spatial import distance\n\nclass BalanceAwarePlanner(Node):\n    """\n    Balance-aware path planner for humanoid robots\n    """\n    def __init__(self):\n        super().__init__(\'balance_aware_planner\')\n\n        # Create subscribers\n        self.path_sub = self.create_subscription(\n            Path,\n            \'/plan\',\n            self.path_callback,\n            10\n        )\n\n        self.costmap_sub = self.create_subscription(\n            OccupancyGrid,\n            \'/global_costmap/costmap\',\n            self.costmap_callback,\n            10\n        )\n\n        self.laser_sub = self.create_subscription(\n            LaserScan,\n            \'/scan\',\n            self.laser_callback,\n            10\n        )\n\n        self.imu_sub = self.create_subscription(\n            Float64,\n            \'/walking_state\',  # From walking motion compensation\n            self.walking_state_callback,\n            10\n        )\n\n        # Create publishers\n        self.balance_path_pub = self.create_publisher(\n            Path,\n            \'/balance_aware_plan\',\n            10\n        )\n\n        self.support_polygon_pub = self.create_publisher(\n            PolygonStamped,\n            \'/support_polygon\',\n            10\n        )\n\n        self.balance_viz_pub = self.create_publisher(\n            MarkerArray,\n            \'/balance_visualization\',\n            10\n        )\n\n        # Initialize variables\n        self.costmap = None\n        self.laser_data = None\n        self.walking_state = 0.0  # 0.0 = standing, 1.0 = walking\n        self.current_support_polygon = []\n        self.balance_margin = 0.15  # 15cm balance margin\n\n        # Robot dimensions (for support polygon)\n        self.foot_length = 0.25\n        self.foot_width = 0.15\n        self.foot_separation = 0.2  # Distance between feet\n\n        self.get_logger().info(\'Balance-aware Planner initialized\')\n\n    def costmap_callback(self, msg):\n        """\n        Store costmap information\n        """\n        self.costmap = msg\n\n    def laser_callback(self, msg):\n        """\n        Store laser scan data for obstacle detection\n        """\n        self.laser_data = msg\n\n    def walking_state_callback(self, msg):\n        """\n        Update walking state for balance planning\n        """\n        self.walking_state = msg.data\n\n    def path_callback(self, msg):\n        """\n        Process incoming path and apply balance constraints\n        """\n        if self.costmap is None:\n            self.get_logger().warn(\'Costmap not received yet\')\n            return\n\n        # Apply balance constraints to path\n        balance_path = self.apply_balance_constraints(msg)\n\n        # Publish balance-aware path\n        self.balance_path_pub.publish(balance_path)\n\n        # Publish support polygon\n        self.publish_support_polygon()\n\n        # Publish visualization\n        self.publish_balance_visualization(balance_path)\n\n    def apply_balance_constraints(self, original_path):\n        """\n        Apply balance constraints to the original path\n        """\n        if len(original_path.poses) < 2:\n            return original_path\n\n        balance_path = Path()\n        balance_path.header = original_path.header\n\n        # Calculate support polygon based on current stance\n        support_polygon = self.calculate_support_polygon()\n\n        for i, pose_stamped in enumerate(original_path.poses):\n            # Get the original position\n            original_pos = np.array([\n                pose_stamped.pose.position.x,\n                pose_stamped.pose.position.y\n            ])\n\n            # Check if position is within balance margin of support polygon\n            balanced_pos = self.ensure_balance(original_pos, support_polygon)\n\n            # Create new pose with balanced position\n            new_pose = PoseStamped()\n            new_pose.header = pose_path.header\n            new_pose.pose.position.x = balanced_pos[0]\n            new_pose.pose.position.y = balanced_pos[1]\n            new_pose.pose.position.z = pose_stamped.pose.position.z\n\n            # Copy orientation\n            new_pose.pose.orientation = pose_stamped.pose.orientation\n\n            balance_path.poses.append(new_pose)\n\n            # Update support polygon for next step\n            if i > 0:  # After first step, update support polygon\n                self.update_support_polygon(balanced_pos)\n\n        return balance_path\n\n    def calculate_support_polygon(self):\n        """\n        Calculate current support polygon based on foot positions\n        """\n        # For standing: rectangular area between feet\n        # For walking: area around single supporting foot\n        if self.walking_state < 0.5:  # Standing\n            # Create rectangular support polygon between feet\n            center_x = 0  # Robot center\n            center_y = 0\n            half_length = self.foot_length / 2 + 0.05  # Add small margin\n            half_width = self.foot_separation / 2 + self.foot_width / 2\n\n            polygon = [\n                (center_x - half_length, center_y - half_width),\n                (center_x + half_length, center_y - half_width),\n                (center_x + half_length, center_y + half_width),\n                (center_x - half_length, center_y + half_width)\n            ]\n        else:  # Walking - single foot support\n            # Simplified: just around the supporting foot\n            support_x = 0\n            support_y = 0  # This would come from actual foot position\n            half_length = self.foot_length / 2\n            half_width = self.foot_width / 2\n\n            polygon = [\n                (support_x - half_length, support_y - half_width),\n                (support_x + half_length, support_y - half_width),\n                (support_x + half_length, support_y + half_width),\n                (support_x - half_length, support_y + half_width)\n            ]\n\n        return polygon\n\n    def ensure_balance(self, target_pos, support_polygon):\n        """\n        Ensure target position is within balance constraints\n        """\n        # Calculate centroid of support polygon\n        centroid_x = sum(p[0] for p in support_polygon) / len(support_polygon)\n        centroid_y = sum(p[1] for p in support_polygon) / len(support_polygon)\n        centroid = np.array([centroid_x, centroid_y])\n\n        # Check if target is within balance margin\n        dist_to_centroid = np.linalg.norm(target_pos - centroid)\n\n        # Calculate max allowable distance based on support polygon\n        max_balance_dist = min(\n            self.foot_length, self.foot_width\n        ) / 2 + self.balance_margin\n\n        if dist_to_centroid > max_balance_dist:\n            # Project target position onto balance boundary\n            direction = (target_pos - centroid) / dist_to_centroid\n            balanced_pos = centroid + direction * max_balance_dist\n            self.get_logger().warn(f\'Adjusting path for balance: {target_pos} -> {balanced_pos}\')\n            return balanced_pos\n        else:\n            return target_pos\n\n    def update_support_polygon(self, foot_pos):\n        """\n        Update support polygon based on new foot position\n        """\n        # This would update the support polygon as the robot moves\n        # For now, just store the position\n        pass\n\n    def publish_support_polygon(self):\n        """\n        Publish current support polygon\n        """\n        polygon_msg = PolygonStamped()\n        polygon_msg.header.stamp = self.get_clock().now().to_msg()\n        polygon_msg.header.frame_id = "base_link"\n\n        # Create polygon points (simplified)\n        support_polygon = self.calculate_support_polygon()\n        for x, y in support_polygon:\n            point = Point()\n            point.x = x\n            point.y = y\n            point.z = 0.0\n            polygon_msg.polygon.points.append(point)\n\n        self.support_polygon_pub.publish(polygon_msg)\n\n    def publish_balance_visualization(self, path):\n        """\n        Publish balance-related visualization markers\n        """\n        marker_array = MarkerArray()\n\n        # Support polygon visualization\n        polygon_marker = Marker()\n        polygon_marker.header.stamp = self.get_clock().now().to_msg()\n        polygon_marker.header.frame_id = "base_link"\n        polygon_marker.ns = "support_polygon"\n        polygon_marker.id = 0\n        polygon_marker.type = Marker.LINE_STRIP\n        polygon_marker.action = Marker.ADD\n\n        # Add points to form the polygon\n        support_polygon = self.calculate_support_polygon()\n        for x, y in support_polygon:\n            point = Point()\n            point.x = x\n            point.y = y\n            point.z = 0.05  # Slightly above ground\n            polygon_marker.points.append(point)\n\n        # Close the polygon\n        if support_polygon:\n            point = Point()\n            point.x = support_polygon[0][0]\n            point.y = support_polygon[0][1]\n            point.z = 0.05\n            polygon_marker.points.append(point)\n\n        polygon_marker.color.r = 0.0\n        polygon_marker.color.g = 1.0\n        polygon_marker.color.b = 0.0\n        polygon_marker.color.a = 0.8\n        polygon_marker.scale.x = 0.02\n\n        marker_array.markers.append(polygon_marker)\n\n        # Path visualization\n        path_marker = Marker()\n        path_marker.header = path.header\n        path_marker.ns = "balance_path"\n        path_marker.id = 1\n        path_marker.type = Marker.LINE_STRIP\n        path_marker.action = Marker.ADD\n\n        for pose_stamped in path.poses:\n            point = Point()\n            point.x = pose_stamped.pose.position.x\n            point.y = pose_stamped.pose.position.y\n            point.z = 0.1  # Above polygon\n            path_marker.points.append(point)\n\n        path_marker.color.r = 1.0\n        path_marker.color.g = 0.0\n        path_marker.color.b = 1.0\n        path_marker.color.a = 0.8\n        path_marker.scale.x = 0.05\n\n        marker_array.markers.append(path_marker)\n\n        self.balance_viz_pub.publish(marker_array)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    balance_planner = BalanceAwarePlanner()\n\n    try:\n        rclpy.spin(balance_planner)\n    except KeyboardInterrupt:\n        balance_planner.get_logger().info(\'Shutting down balance-aware planner\')\n    finally:\n        balance_planner.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,o.jsx)(e.h2,{id:"stair-and-multi-floor-navigation",children:"Stair and Multi-Floor Navigation"}),"\n",(0,o.jsx)(e.h3,{id:"1-stair-navigation-planning",children:"1. Stair Navigation Planning"}),"\n",(0,o.jsx)(e.p,{children:"Implementing navigation for stairs and multi-floor environments:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\n# stair_navigation.py\n\nimport rclpy\nfrom rclpy.node import Node\nfrom nav_msgs.msg import Path\nfrom geometry_msgs.msg import PoseStamped, Point\nfrom visualization_msgs.msg import MarkerArray\nfrom sensor_msgs.msg import LaserScan\nfrom std_msgs.msg import Int8\nimport numpy as np\nimport math\n\nclass StairNavigation(Node):\n    """\n    Stair navigation system for humanoid robots\n    """\n    def __init__(self):\n        super().__init__(\'stair_navigation\')\n\n        # Create subscribers\n        self.path_sub = self.create_subscription(\n            Path,\n            \'/plan\',\n            self.path_callback,\n            10\n        )\n\n        self.laser_sub = self.create_subscription(\n            LaserScan,\n            \'/scan\',\n            self.laser_callback,\n            10\n        )\n\n        # Create publishers\n        self.stair_path_pub = self.create_publisher(\n            Path,\n            \'/stair_navigation_plan\',\n            10\n        )\n\n        self.stair_type_pub = self.create_publisher(\n            Int8,\n            \'/stair_type\',\n            10\n        )\n\n        self.stair_viz_pub = self.create_publisher(\n            MarkerArray,\n            \'/stair_visualization\',\n            10\n        )\n\n        # Initialize variables\n        self.laser_data = None\n        self.floor_height = 0.0  # Current floor height\n        self.step_height = 0.15  # 15cm per step (typical)\n        self.step_depth = 0.30   # 30cm depth (typical)\n\n        # Stair detection parameters\n        self.stair_threshold = 0.1  # Height difference threshold\n        self.min_stair_steps = 3    # Minimum steps to qualify as stairs\n\n        self.get_logger().info(\'Stair Navigation initialized\')\n\n    def laser_callback(self, msg):\n        """\n        Process laser scan data for stair detection\n        """\n        self.laser_data = msg\n        self.detect_stairs()\n\n    def path_callback(self, msg):\n        """\n        Process incoming path and adapt for stairs\n        """\n        if len(msg.poses) < 2:\n            self.stair_path_pub.publish(msg)\n            return\n\n        # Check if path involves stairs\n        stair_path = self.adapt_path_for_stairs(msg)\n\n        # Publish stair-adapted path\n        self.stair_path_pub.publish(stair_path)\n\n        # Publish stair visualization\n        self.publish_stair_visualization(stair_path)\n\n    def detect_stairs(self):\n        """\n        Detect stairs in laser scan data\n        """\n        if self.laser_data is None:\n            return\n\n        # Analyze laser data for step patterns\n        ranges = np.array(self.laser_data.ranges)\n        angles = np.linspace(\n            self.laser_data.angle_min,\n            self.laser_data.angle_max,\n            len(ranges)\n        )\n\n        # Convert to Cartesian coordinates\n        x_coords = ranges * np.cos(angles)\n        y_coords = ranges * np.sin(angles)\n\n        # Look for step-like patterns in the data\n        # This is a simplified approach - real implementation would be more sophisticated\n        height_changes = np.diff(y_coords)\n        potential_steps = np.where(np.abs(height_changes) > self.stair_threshold)[0]\n\n        if len(potential_steps) >= self.min_stair_steps:\n            # Likely stairs detected\n            stair_msg = Int8()\n            stair_msg.data = 1  # Stairs detected\n            self.stair_type_pub.publish(stair_msg)\n            self.get_logger().info(\'Stairs detected in environment\')\n        else:\n            # No stairs\n            stair_msg = Int8()\n            stair_msg.data = 0  # No stairs\n            self.stair_type_pub.publish(stair_msg)\n\n    def adapt_path_for_stairs(self, original_path):\n        """\n        Adapt path for stair navigation\n        """\n        if len(original_path.poses) < 2:\n            return original_path\n\n        stair_path = Path()\n        stair_path.header = original_path.header\n\n        # For stair navigation, we need to plan each step explicitly\n        # This is a simplified approach - real implementation would be more detailed\n        current_height = self.floor_height\n\n        for i in range(len(original_path.poses)):\n            original_pose = original_path.poses[i]\n\n            # Create stair-adapted pose\n            stair_pose = PoseStamped()\n            stair_pose.header = original_path.header\n\n            # Copy position (for now, in real implementation, adjust for steps)\n            stair_pose.pose.position.x = original_pose.pose.position.x\n            stair_pose.pose.position.y = original_pose.pose.position.y\n\n            # For stairs, we need to account for step height\n            if self.is_approaching_stairs(original_pose):\n                # Calculate appropriate Z height for this step\n                step_number = self.calculate_step_number(original_pose)\n                stair_pose.pose.position.z = self.floor_height + (step_number * self.step_height)\n            else:\n                stair_pose.pose.position.z = self.floor_height\n\n            # Copy orientation\n            stair_pose.pose.orientation = original_pose.pose.orientation\n\n            stair_path.poses.append(stair_pose)\n\n        return stair_path\n\n    def is_approaching_stairs(self, pose):\n        """\n        Check if the robot is approaching stairs\n        """\n        # This would use more sophisticated detection in real implementation\n        # For now, return False to avoid complications\n        return False\n\n    def calculate_step_number(self, pose):\n        """\n        Calculate which step the robot should be on\n        """\n        # This would be calculated based on the path and stair location\n        # For now, return a simple increment\n        return 0\n\n    def publish_stair_visualization(self, path):\n        """\n        Publish stair-related visualization\n        """\n        marker_array = MarkerArray()\n\n        # Visualize the path adapted for stairs\n        path_marker = Marker()\n        path_marker.header = path.header\n        path_marker.ns = "stair_path"\n        path_marker.id = 0\n        path_marker.type = Marker.LINE_STRIP\n        path_marker.action = Marker.ADD\n\n        for pose_stamped in path.poses:\n            point = Point()\n            point.x = pose_stamped.pose.position.x\n            point.y = pose_stamped.pose.position.y\n            point.z = pose_stamped.pose.position.z\n            path_marker.points.append(point)\n\n        path_marker.color.r = 0.0\n        path_marker.color.g = 1.0\n        path_marker.color.b = 1.0\n        path_marker.color.a = 0.8\n        path_marker.scale.x = 0.05\n\n        marker_array.markers.append(path_marker)\n\n        # If stairs are detected, visualize them\n        if self.laser_data is not None:\n            # Create stair visualization markers\n            stair_marker = Marker()\n            stair_marker.header = path.header\n            stair_marker.ns = "detected_stairs"\n            stair_marker.id = 1\n            stair_marker.type = Marker.CUBE_LIST\n            stair_marker.action = Marker.ADD\n\n            # Add points for stair visualization\n            # This is a simplified visualization\n            for step in range(5):  # Visualize 5 steps\n                point = Point()\n                point.x = 2.0  # Position of stairs\n                point.y = step * self.step_depth\n                point.z = step * self.step_height + self.step_height / 2\n                stair_marker.points.append(point)\n\n            stair_marker.color.r = 1.0\n            stair_marker.color.g = 0.5\n            stair_marker.color.b = 0.0\n            stair_marker.color.a = 0.8\n            stair_marker.scale.x = self.step_depth\n            stair_marker.scale.y = 0.2\n            stair_marker.scale.z = self.step_height\n\n            marker_array.markers.append(stair_marker)\n\n        self.stair_viz_pub.publish(marker_array)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    stair_nav = StairNavigation()\n\n    try:\n        rclpy.spin(stair_nav)\n    except KeyboardInterrupt:\n        stair_nav.get_logger().info(\'Shutting down stair navigation\')\n    finally:\n        stair_nav.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,o.jsx)(e.h2,{id:"humanoid-navigation-controller",children:"Humanoid Navigation Controller"}),"\n",(0,o.jsx)(e.h3,{id:"1-walking-controller-integration",children:"1. Walking Controller Integration"}),"\n",(0,o.jsx)(e.p,{children:"Creating a humanoid-specific navigation controller:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:'#!/usr/bin/env python3\n# humanoid_navigation_controller.py\n\nimport rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import Twist, PoseStamped\nfrom nav_msgs.msg import Path, Odometry\nfrom sensor_msgs.msg import Imu, JointState\nfrom std_msgs.msg import Float64, Bool\nimport numpy as np\nimport math\nfrom tf2_ros import TransformListener, Buffer\nimport tf2_geometry_msgs\n\nclass HumanoidNavigationController(Node):\n    """\n    Navigation controller specifically designed for humanoid robots\n    """\n    def __init__(self):\n        super().__init__(\'humanoid_navigation_controller\')\n\n        # Create subscribers\n        self.cmd_vel_sub = self.create_subscription(\n            Twist,\n            \'/cmd_vel\',\n            self.cmd_vel_callback,\n            10\n        )\n\n        self.path_sub = self.create_subscription(\n            Path,\n            \'/footstep_plan\',  # From footstep planner\n            self.path_callback,\n            10\n        )\n\n        self.odom_sub = self.create_subscription(\n            Odometry,\n            \'/odom\',\n            self.odom_callback,\n            10\n        )\n\n        self.imu_sub = self.create_subscription(\n            Imu,\n            \'/imu/data\',\n            self.imu_callback,\n            10\n        )\n\n        self.joint_state_sub = self.create_subscription(\n            JointState,\n            \'/joint_states\',\n            self.joint_state_callback,\n            10\n        )\n\n        # Create publishers\n        self.velocity_cmd_pub = self.create_publisher(\n            Twist,\n            \'/humanoid_velocity_controller/cmd_vel\',\n            10\n        )\n\n        self.balance_state_pub = self.create_publisher(\n            Bool,\n            \'/balance_state\',\n            10\n        )\n\n        self.step_command_pub = self.create_publisher(\n            Float64,\n            \'/step_command\',\n            10\n        )\n\n        # Initialize TF listener\n        self.tf_buffer = Buffer()\n        self.tf_listener = TransformListener(self.tf_buffer, self)\n\n        # Robot state\n        self.current_pose = np.array([0.0, 0.0, 0.0])  # x, y, theta\n        self.current_velocity = np.array([0.0, 0.0, 0.0])  # vx, vy, wz\n        self.imu_data = None\n        self.joint_states = None\n        self.current_path = []\n        self.path_index = 0\n\n        # Walking parameters\n        self.step_size = 0.3  # 30cm step\n        self.step_height = 0.05  # 5cm step height\n        self.walking_speed = 0.3  # 0.3 m/s walking speed\n        self.balance_threshold = 0.1  # Balance threshold\n\n        # Control parameters\n        self.linear_kp = 1.0\n        self.angular_kp = 2.0\n        self.max_linear_vel = 0.4\n        self.max_angular_vel = 0.8\n\n        # Walking state machine\n        self.walking_state = "standing"  # standing, stepping, walking\n        self.step_phase = 0.0  # 0.0 to 1.0\n\n        self.get_logger().info(\'Humanoid Navigation Controller initialized\')\n\n    def cmd_vel_callback(self, msg):\n        """\n        Handle velocity commands\n        """\n        # In humanoid navigation, we might need to convert this\n        # to step-based commands rather than direct velocity\n        self.execute_navigation_command(msg)\n\n    def path_callback(self, msg):\n        """\n        Handle path following commands\n        """\n        self.current_path = msg.poses\n        self.path_index = 0\n        self.get_logger().info(f\'New path received with {len(self.current_path)} waypoints\')\n\n    def odom_callback(self, msg):\n        """\n        Update robot pose from odometry\n        """\n        self.current_pose[0] = msg.pose.pose.position.x\n        self.current_pose[1] = msg.pose.pose.position.y\n\n        # Convert quaternion to euler\n        quat = msg.pose.pose.orientation\n        siny_cosp = 2 * (quat.w * quat.z + quat.x * quat.y)\n        cosy_cosp = 1 - 2 * (quat.y * quat.y + quat.z * quat.z)\n        self.current_pose[2] = math.atan2(siny_cosp, cosy_cosp)\n\n        # Update velocity\n        self.current_velocity[0] = msg.twist.twist.linear.x\n        self.current_velocity[1] = msg.twist.twist.linear.y\n        self.current_velocity[2] = msg.twist.twist.angular.z\n\n    def imu_callback(self, msg):\n        """\n        Store IMU data for balance control\n        """\n        self.imu_data = msg\n\n    def joint_state_callback(self, msg):\n        """\n        Store joint state data\n        """\n        self.joint_states = msg\n\n    def execute_navigation_command(self, cmd_vel):\n        """\n        Execute navigation command with humanoid-specific control\n        """\n        # Check balance before executing command\n        if not self.is_balanced():\n            self.get_logger().warn(\'Robot is not balanced, stopping navigation\')\n            stop_cmd = Twist()\n            self.velocity_cmd_pub.publish(stop_cmd)\n            return\n\n        # For humanoid robots, we might need to convert linear/angular\n        # commands to step-based commands\n        humanoid_cmd = self.convert_to_humanoid_command(cmd_vel)\n\n        # Publish the command\n        self.velocity_cmd_pub.publish(humanoid_cmd)\n\n        # Update walking state\n        if abs(cmd_vel.linear.x) > 0.01 or abs(cmd_vel.angular.z) > 0.01:\n            self.walking_state = "walking"\n        else:\n            self.walking_state = "standing"\n\n    def convert_to_humanoid_command(self, cmd_vel):\n        """\n        Convert standard velocity command to humanoid-appropriate command\n        """\n        humanoid_cmd = Twist()\n\n        # Apply humanoid-specific constraints\n        linear_x = max(-self.max_linear_vel, min(self.max_linear_vel, cmd_vel.linear.x))\n        angular_z = max(-self.max_angular_vel, min(self.max_angular_vel, cmd_vel.angular.z))\n\n        # For humanoid, we might want to convert to step commands\n        # For now, just apply constraints\n        humanoid_cmd.linear.x = linear_x\n        humanoid_cmd.angular.z = angular_z\n\n        # Keep other components zero\n        humanoid_cmd.linear.y = cmd_vel.linear.y\n        humanoid_cmd.linear.z = cmd_vel.linear.z\n        humanoid_cmd.angular.x = cmd_vel.angular.x\n        humanoid_cmd.angular.y = cmd_vel.angular.y\n\n        return humanoid_cmd\n\n    def is_balanced(self):\n        """\n        Check if robot is in balanced state using IMU data\n        """\n        if self.imu_data is None:\n            return True  # Assume balanced if no data\n\n        # Check if orientation is within balance limits\n        quat = self.imu_data.orientation\n        # Convert to roll/pitch to check balance\n        sinr_cosp = 2 * (quat.w * quat.x + quat.y * quat.z)\n        cosr_cosp = 1 - 2 * (quat.x * quat.x + quat.y * quat.y)\n        roll = math.atan2(sinr_cosp, cosr_cosp)\n\n        sinp = 2 * (quat.w * quat.y - quat.z * quat.x)\n        pitch = math.asin(sinp)\n\n        # Check if roll and pitch are within balance thresholds\n        if abs(roll) > self.balance_threshold or abs(pitch) > self.balance_threshold:\n            return False\n\n        return True\n\n    def follow_path(self):\n        """\n        Follow the current path using humanoid-specific control\n        """\n        if not self.current_path or self.path_index >= len(self.current_path):\n            return\n\n        # Get the next waypoint\n        target_pose = self.current_path[self.path_index]\n        target_x = target_pose.pose.position.x\n        target_y = target_pose.pose.position.y\n\n        # Calculate distance to target\n        dx = target_x - self.current_pose[0]\n        dy = target_y - self.current_pose[1]\n        distance = math.sqrt(dx*dx + dy*dy)\n\n        # Calculate target angle\n        target_angle = math.atan2(dy, dx)\n        angle_diff = target_angle - self.current_pose[2]\n\n        # Normalize angle difference\n        while angle_diff > math.pi:\n            angle_diff -= 2 * math.pi\n        while angle_diff < -math.pi:\n            angle_diff += 2 * math.pi\n\n        # Create command to follow path\n        cmd_vel = Twist()\n        cmd_vel.linear.x = min(self.max_linear_vel, self.linear_kp * distance)\n        cmd_vel.angular.z = min(self.max_angular_vel, self.angular_kp * angle_diff)\n\n        # Check if we\'ve reached this waypoint\n        if distance < 0.2:  # Waypoint tolerance\n            self.path_index += 1\n            if self.path_index >= len(self.current_path):\n                self.get_logger().info(\'Path completed\')\n                cmd_vel.linear.x = 0.0\n                cmd_vel.angular.z = 0.0\n\n        # Execute the command\n        self.execute_navigation_command(cmd_vel)\n\n    def step_callback(self):\n        """\n        Timer callback for step-based control\n        """\n        if self.walking_state == "walking" and self.current_path:\n            self.follow_path()\n\n        # Publish balance state\n        balance_msg = Bool()\n        balance_msg.data = self.is_balanced()\n        self.balance_state_pub.publish(balance_msg)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    controller = HumanoidNavigationController()\n\n    # Create timer for path following\n    controller.create_timer(0.1, controller.step_callback)  # 10Hz\n\n    try:\n        rclpy.spin(controller)\n    except KeyboardInterrupt:\n        controller.get_logger().info(\'Shutting down humanoid navigation controller\')\n    finally:\n        # Stop the robot on shutdown\n        stop_cmd = Twist()\n        controller.velocity_cmd_pub.publish(stop_cmd)\n        controller.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,o.jsx)(e.h2,{id:"complete-navigation-launch-files",children:"Complete Navigation Launch Files"}),"\n",(0,o.jsx)(e.h3,{id:"1-humanoid-navigation-launch",children:"1. Humanoid Navigation Launch"}),"\n",(0,o.jsx)(e.p,{children:"Creating launch files for the complete humanoid navigation system:"}),"\n",(0,o.jsx)(e.pre,{children:(0,o.jsx)(e.code,{className:"language-python",children:"# launch/humanoid_navigation.launch.py\n\nfrom launch import LaunchDescription\nfrom launch.actions import DeclareLaunchArgument, GroupAction, RegisterEventHandler\nfrom launch.event_handlers import OnProcessStart\nfrom launch.substitutions import LaunchConfiguration, PathJoinSubstitution\nfrom launch_ros.actions import Node, SetParameter\nfrom launch_ros.substitutions import FindPackageShare\nfrom nav2_common.launch import ReplaceString\n\ndef generate_launch_description():\n    # Launch arguments\n    use_sim_time = LaunchConfiguration('use_sim_time')\n    autostart = LaunchConfiguration('autostart')\n    params_file = LaunchConfiguration('params_file')\n    use_composition = LaunchConfiguration('use_composition')\n    container_name = LaunchConfiguration('container_name')\n    container_name_full = (container_name, '_container')\n\n    # Declare launch arguments\n    declare_use_sim_time = DeclareLaunchArgument(\n        'use_sim_time',\n        default_value='false',\n        description='Use simulation time'\n    )\n\n    declare_autostart = DeclareLaunchArgument(\n        'autostart',\n        default_value='true',\n        description='Automatically startup the nav2 stack'\n    )\n\n    declare_params_file = DeclareLaunchArgument(\n        'params_file',\n        default_value=PathJoinSubstitution([\n            FindPackageShare('humanoid_nav2'),\n            'config',\n            'humanoid_nav2_params.yaml'\n        ]),\n        description='Full path to the ROS2 parameters file to use for all launched nodes'\n    )\n\n    declare_use_composition = DeclareLaunchArgument(\n        'use_composition',\n        default_value='False',\n        description='Use composed bringup if True'\n    )\n\n    declare_container_name = DeclareLaunchArgument(\n        'container_name',\n        default_value='nav2_container',\n        description='the name of conatiner that nodes will load in if use composition'\n    )\n\n    # Robot description (for transforms)\n    robot_description = {'robot_description':\n        PathJoinSubstitution([\n            FindPackageShare('humanoid_description'),\n            'urdf',\n            'humanoid.urdf'\n        ])\n    }\n\n    # Static transform publisher for robot base\n    static_transform_publisher = Node(\n        package='tf2_ros',\n        executable='static_transform_publisher',\n        name='static_transform_publisher',\n        arguments=['0', '0', '0', '0', '0', '0', 'odom', 'base_link']\n    )\n\n    # Navigation lifecycle manager\n    lifecycle_manager = Node(\n        package='nav2_lifecycle_manager',\n        executable='lifecycle_manager',\n        name='lifecycle_manager',\n        output='screen',\n        parameters=[{'use_sim_time': use_sim_time},\n                    {'autostart': autostart},\n                    {'node_names': ['map_server',\n                                   'planner_server',\n                                   'controller_server',\n                                   'behavior_server',\n                                   'bt_navigator',\n                                   'waypoint_follower',\n                                   'velocity_smoother']}]\n    )\n\n    # Footstep planner node\n    footstep_planner = Node(\n        package='humanoid_nav2',\n        executable='footstep_planner',\n        name='footstep_planner',\n        parameters=[{'use_sim_time': use_sim_time}],\n        remappings=[\n            ('/plan', '/global_costmap/costmap_updates'),\n            ('/footstep_plan', '/footstep_plan'),\n        ]\n    )\n\n    # Balance-aware planner node\n    balance_planner = Node(\n        package='humanoid_nav2',\n        executable='balance_aware_planner',\n        name='balance_aware_planner',\n        parameters=[{'use_sim_time': use_sim_time}],\n        remappings=[\n            ('/plan', '/plan'),\n            ('/balance_aware_plan', '/balance_aware_plan'),\n        ]\n    )\n\n    # Stair navigation node\n    stair_navigation = Node(\n        package='humanoid_nav2',\n        executable='stair_navigation',\n        name='stair_navigation',\n        parameters=[{'use_sim_time': use_sim_time}],\n        remappings=[\n            ('/scan', '/scan'),\n            ('/stair_navigation_plan', '/stair_navigation_plan'),\n        ]\n    )\n\n    # Humanoid navigation controller\n    humanoid_controller = Node(\n        package='humanoid_nav2',\n        executable='humanoid_navigation_controller',\n        name='humanoid_navigation_controller',\n        parameters=[{'use_sim_time': use_sim_time}],\n        remappings=[\n            ('/cmd_vel', '/cmd_vel'),\n            ('/footstep_plan', '/footstep_plan'),\n        ]\n    )\n\n    # AMCL localization node\n    amcl = Node(\n        package='nav2_amcl',\n        executable='amcl',\n        name='amcl',\n        parameters=[params_file, {'use_sim_time': use_sim_time}],\n        remappings=[('scan', 'scan')]\n    )\n\n    # Map server\n    map_server = Node(\n        package='nav2_map_server',\n        executable='map_server',\n        name='map_server',\n        parameters=[params_file, {'use_sim_time': use_sim_time}],\n        remappings=[('map', 'map'),\n                   ('map_metadata', 'map_metadata')]\n    )\n\n    # Planner server\n    planner_server = Node(\n        package='nav2_planner',\n        executable='planner_server',\n        name='planner_server',\n        parameters=[params_file, {'use_sim_time': use_sim_time}],\n        remappings=[('~/global_costmap/costmap', 'global_costmap/costmap'),\n                   ('~/global_costmap/costmap_updates', 'global_costmap/costmap_updates')]\n    )\n\n    # Controller server\n    controller_server = Node(\n        package='nav2_controller',\n        executable='controller_server',\n        name='controller_server',\n        parameters=[params_file, {'use_sim_time': use_sim_time}],\n        remappings=[('cmd_vel', 'cmd_vel'),\n                   ('~/local_costmap/costmap', 'local_costmap/costmap'),\n                   ('~/local_costmap/costmap_updates', 'local_costmap/costmap_updates'),\n                   ('~/global_costmap/costmap', 'global_costmap/costmap')]\n    )\n\n    # Behavior server\n    behavior_server = Node(\n        package='nav2_behaviors',\n        executable='behavior_server',\n        name='behavior_server',\n        parameters=[params_file, {'use_sim_time': use_sim_time}],\n        remappings=[('cmd_vel', 'cmd_vel'),\n                   ('/local_costmap/costmap', '/local_costmap/costmap'),\n                   ('/local_costmap/costmap_updates', '/local_costmap/costmap_updates')]\n    )\n\n    # BT Navigator\n    bt_navigator = Node(\n        package='nav2_bt_navigator',\n        executable='bt_navigator',\n        name='bt_navigator',\n        parameters=[params_file, {'use_sim_time': use_sim_time}],\n        remappings=[('navigate_to_pose', 'navigate_to_pose'),\n                   ('navigate_through_poses', 'navigate_through_poses')]\n    )\n\n    # Waypoint follower\n    waypoint_follower = Node(\n        package='nav2_waypoint_follower',\n        executable='waypoint_follower',\n        name='waypoint_follower',\n        parameters=[params_file, {'use_sim_time': use_sim_time}],\n        remappings=[('cmd_vel', 'cmd_vel')]\n    )\n\n    # Velocity smoother\n    velocity_smoother = Node(\n        package='nav2_velocity_smoother',\n        executable='velocity_smoother',\n        name='velocity_smoother',\n        parameters=[params_file, {'use_sim_time': use_sim_time}],\n        remappings=[('cmd_vel', 'cmd_vel'),\n                   ('smoothed_cmd_vel', 'smoothed_cmd_vel')]\n    )\n\n    # Lifecycle manager should start after other nodes\n    delayed_lifecycle_manager = RegisterEventHandler(\n        OnProcessStart(\n            target_action=velocity_smoother,\n            on_start=[lifecycle_manager]\n        )\n    )\n\n    # Create groups for organized launching\n    navigation_group = GroupAction(\n        actions=[\n            SetParameter('use_sim_time', use_sim_time),\n            amcl,\n            map_server,\n            planner_server,\n            controller_server,\n            behavior_server,\n            bt_navigator,\n            waypoint_follower,\n            velocity_smoother\n        ]\n    )\n\n    humanoid_group = GroupAction(\n        actions=[\n            SetParameter('use_sim_time', use_sim_time),\n            footstep_planner,\n            balance_planner,\n            stair_navigation,\n            humanoid_controller\n        ]\n    )\n\n    return LaunchDescription([\n        declare_use_sim_time,\n        declare_autostart,\n        declare_params_file,\n        declare_use_composition,\n        declare_container_name,\n\n        static_transform_publisher,\n\n        navigation_group,\n        humanoid_group,\n\n        delayed_lifecycle_manager\n    ])\n"})}),"\n",(0,o.jsx)(e.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,o.jsx)(e.p,{children:"With Nav2 properly configured for bipedal navigation, you're ready to move on to the Module 3 project. The next section will integrate all the components you've learned about - Isaac Sim, Isaac ROS perception, VSLAM, and Nav2 navigation - into a complete AI-powered humanoid navigation system."}),"\n",(0,o.jsx)(e.p,{children:"This comprehensive system will demonstrate how to combine photorealistic simulation, hardware-accelerated perception, visual-inertial SLAM, and balance-aware navigation to create an intelligent humanoid robot capable of autonomous navigation in complex environments."})]})}function c(n={}){const{wrapper:e}={...(0,i.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(_,{...n})}):_(n)}},8453:(n,e,a)=>{a.d(e,{R:()=>s,x:()=>r});var t=a(6540);const o={},i=t.createContext(o);function s(n){const e=t.useContext(i);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:s(n.components),t.createElement(i.Provider,{value:e},n.children)}}}]);