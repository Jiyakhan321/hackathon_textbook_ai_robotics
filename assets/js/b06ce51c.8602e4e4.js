"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[3062],{1083:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>m,frontMatter:()=>i,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"module-3-ai-robot-brain/module-3-project","title":"Module 3 Project: Complete AI-Powered Humanoid Navigation System","description":"Overview","source":"@site/docs/module-3-ai-robot-brain/module-3-project.md","sourceDirName":"module-3-ai-robot-brain","slug":"/module-3-ai-robot-brain/module-3-project","permalink":"/hackathon_textbook_ai_robotics/docs/module-3-ai-robot-brain/module-3-project","draft":false,"unlisted":false,"editUrl":"https://github.com/Jiyakhan321/hackathon_textbook_ai_robotics/tree/main/docs/module-3-ai-robot-brain/module-3-project.md","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{"sidebar_position":7},"sidebar":"tutorialSidebar","previous":{"title":"Photorealistic Simulation and Synthetic Data Generation","permalink":"/hackathon_textbook_ai_robotics/docs/module-3-ai-robot-brain/practical-exercises/photorealistic-simulation"},"next":{"title":"Module 4: Vision-Language-Action (VLA) for Humanoid Robots","permalink":"/hackathon_textbook_ai_robotics/docs/module-4-vision-language-action/intro"}}');var s=a(4848),o=a(8453);const i={sidebar_position:7},r="Module 3 Project: Complete AI-Powered Humanoid Navigation System",l={},c=[{value:"Overview",id:"overview",level:2},{value:"Project Objectives",id:"project-objectives",level:2},{value:"System Architecture",id:"system-architecture",level:2},{value:"1. Integrated Architecture Overview",id:"1-integrated-architecture-overview",level:3},{value:"Implementation Phase 1: System Integration",id:"implementation-phase-1-system-integration",level:2},{value:"1. Complete System Launch File",id:"1-complete-system-launch-file",level:3},{value:"2. Complete System Configuration",id:"2-complete-system-configuration",level:3},{value:"Implementation Phase 2: System Validation",id:"implementation-phase-2-system-validation",level:2},{value:"1. System Validation Node",id:"1-system-validation-node",level:3},{value:"Implementation Phase 3: Performance Optimization",id:"implementation-phase-3-performance-optimization",level:2},{value:"1. System Performance Monitor",id:"1-system-performance-monitor",level:3},{value:"Implementation Phase 4: Testing and Demonstration",id:"implementation-phase-4-testing-and-demonstration",level:2},{value:"1. Navigation Test Scenarios",id:"1-navigation-test-scenarios",level:3},{value:"Performance Metrics and Evaluation",id:"performance-metrics-and-evaluation",level:2},{value:"1. Comprehensive Performance Evaluation",id:"1-comprehensive-performance-evaluation",level:3},{value:"Troubleshooting Guide",id:"troubleshooting-guide",level:2},{value:"1. Common Issues and Solutions",id:"1-common-issues-and-solutions",level:3},{value:"Localization Issues",id:"localization-issues",level:4},{value:"Navigation Failures",id:"navigation-failures",level:4},{value:"Performance Issues",id:"performance-issues",level:4},{value:"Balance Problems",id:"balance-problems",level:4},{value:"Next Steps",id:"next-steps",level:2}];function _(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"module-3-project-complete-ai-powered-humanoid-navigation-system",children:"Module 3 Project: Complete AI-Powered Humanoid Navigation System"})}),"\n",(0,s.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsx)(n.p,{children:"In this comprehensive project, you'll integrate all the components learned in Module 3 to create a complete AI-powered humanoid navigation system. This system combines Isaac Sim for photorealistic simulation, Isaac ROS for hardware-accelerated perception, VSLAM for localization and mapping, and Nav2 for balance-aware navigation."}),"\n",(0,s.jsx)(n.p,{children:"The project demonstrates the integration of multiple advanced technologies to create an intelligent humanoid robot capable of autonomous navigation in complex environments."}),"\n",(0,s.jsx)(n.h2,{id:"project-objectives",children:"Project Objectives"}),"\n",(0,s.jsx)(n.p,{children:"By completing this project, you will:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Integrate Isaac Sim, Isaac ROS perception, VSLAM, and Nav2"}),"\n",(0,s.jsx)(n.li,{children:"Implement a complete AI-powered navigation pipeline"}),"\n",(0,s.jsx)(n.li,{children:"Demonstrate autonomous navigation in complex environments"}),"\n",(0,s.jsx)(n.li,{children:"Validate the system's performance in simulation"}),"\n",(0,s.jsx)(n.li,{children:"Prepare for real-world deployment considerations"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"system-architecture",children:"System Architecture"}),"\n",(0,s.jsx)(n.h3,{id:"1-integrated-architecture-overview",children:"1. Integrated Architecture Overview"}),"\n",(0,s.jsx)(n.p,{children:"The complete AI-powered humanoid navigation system consists of interconnected components:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                 COMPLETE HUMANOID NAVIGATION SYSTEM             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n\u2502  \u2502  SIMULATION \u2502  \u2502  PERCEPTION \u2502  \u2502   VSLAM     \u2502  \u2502 NAV2    \u2502\u2502\n\u2502  \u2502             \u2502  \u2502             \u2502  \u2502             \u2502  \u2502         \u2502\u2502\n\u2502  \u2502 \u2022 Isaac Sim \u2502  \u2502 \u2022 Isaac ROS \u2502  \u2502 \u2022 Visual    \u2502  \u2502 \u2022 Global\u2502\u2502\n\u2502  \u2502 \u2022 Physics   \u2502  \u2502 \u2022 VIO       \u2502  \u2502   Odometry  \u2502  \u2502   Planner\u2502\u2502\n\u2502  \u2502 \u2022 Sensors   \u2502  \u2502 \u2022 Apriltag  \u2502  \u2502 \u2022 Mapping   \u2502  \u2502 \u2022 Local \u2502\u2502\n\u2502  \u2502             \u2502  \u2502 \u2022 DNN       \u2502  \u2502             \u2502  \u2502   Planner\u2502\u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\n\u2502                              \u2502                                  \u2502\n\u2502                              \u25bc                                  \u2502\n\u2502                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                  \u2502\n\u2502                    \u2502   HUMANOID CONTROLLER   \u2502                  \u2502\n\u2502                    \u2502 \u2022 Footstep Planning     \u2502                  \u2502\n\u2502                    \u2502 \u2022 Balance Control       \u2502                  \u2502\n\u2502                    \u2502 \u2022 Walking Control       \u2502                  \u2502\n\u2502                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,s.jsx)(n.h2,{id:"implementation-phase-1-system-integration",children:"Implementation Phase 1: System Integration"}),"\n",(0,s.jsx)(n.h3,{id:"1-complete-system-launch-file",children:"1. Complete System Launch File"}),"\n",(0,s.jsx)(n.p,{children:"Creating the main launch file that brings up the entire system:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# launch/complete_humanoid_navigation_system.launch.py\n\nfrom launch import LaunchDescription\nfrom launch.actions import DeclareLaunchArgument, GroupAction, RegisterEventHandler\nfrom launch.event_handlers import OnProcessStart\nfrom launch.substitutions import LaunchConfiguration, PathJoinSubstitution\nfrom launch_ros.actions import Node, SetParameter, PushRosNamespace\nfrom launch_ros.substitutions import FindPackageShare\nfrom nav2_common.launch import ReplaceString\n\ndef generate_launch_description():\n    # Launch arguments\n    use_sim_time = LaunchConfiguration('use_sim_time')\n    autostart = LaunchConfiguration('autostart')\n    params_file = LaunchConfiguration('params_file')\n    robot_name = LaunchConfiguration('robot_name')\n    namespace = LaunchConfiguration('namespace')\n\n    # Declare launch arguments\n    declare_use_sim_time = DeclareLaunchArgument(\n        'use_sim_time',\n        default_value='true',\n        description='Use simulation time'\n    )\n\n    declare_autostart = DeclareLaunchArgument(\n        'autostart',\n        default_value='true',\n        description='Automatically startup the nav2 stack'\n    )\n\n    declare_params_file = DeclareLaunchArgument(\n        'params_file',\n        default_value=PathJoinSubstitution([\n            FindPackageShare('humanoid_navigation_system'),\n            'config',\n            'complete_nav_params.yaml'\n        ]),\n        description='Full path to the ROS2 parameters file'\n    )\n\n    declare_robot_name = DeclareLaunchArgument(\n        'robot_name',\n        default_value='humanoid_robot',\n        description='Name of the robot'\n    )\n\n    declare_namespace = DeclareLaunchArgument(\n        'namespace',\n        default_value='',\n        description='Top-level namespace'\n    )\n\n    # Robot state publisher\n    robot_state_publisher = Node(\n        package='robot_state_publisher',\n        executable='robot_state_publisher',\n        name='robot_state_publisher',\n        parameters=[{\n            'use_sim_time': use_sim_time,\n            'robot_description': PathJoinSubstitution([\n                FindPackageShare('humanoid_description'),\n                'urdf',\n                'humanoid.urdf'\n            ])\n        }]\n    )\n\n    # Static transform publishers\n    static_transforms = [\n        Node(\n            package='tf2_ros',\n            executable='static_transform_publisher',\n            name=f'static_transform_publisher_{i}',\n            arguments=transform_args,\n            condition=IfCondition(LaunchConfiguration('publish_static_transforms'))\n        )\n        for i, transform_args in enumerate([\n            ['0', '0', '0', '0', '0', '0', 'odom', 'base_link'],\n            ['0.1', '0', '0.1', '0', '0', '0', 'base_link', 'camera_link'],\n            ['0', '0', '0.8', '0', '0', '0', 'base_link', 'imu_link']\n        ])\n    ]\n\n    # Isaac ROS Visual Inertial Odometry\n    vio_node = Node(\n        package='isaac_ros_visual_inertial_odometry',\n        executable='visual_inertial_odometry_node',\n        name='visual_inertial_odometry',\n        parameters=[{\n            'use_sim_time': use_sim_time,\n            'enable_debug_mode': False,\n            'publish_tf': True,\n            'world_frame': 'odom',\n            'base_frame': 'base_link'\n        }],\n        remappings=[\n            ('left/image_rect', '/stereo/left/image_rect'),\n            ('left/camera_info', '/stereo/left/camera_info'),\n            ('right/image_rect', '/stereo/right/image_rect'),\n            ('right/camera_info', '/stereo/right/camera_info'),\n            ('imu', '/imu/data'),\n            ('visual_odometry', '/visual_odometry'),\n        ]\n    )\n\n    # Isaac ROS Apriltag detector\n    apriltag_node = Node(\n        package='isaac_ros_apriltag',\n        executable='apriltag_node',\n        name='apriltag',\n        parameters=[{\n            'use_sim_time': use_sim_time,\n            'family': 'tag36h11',\n            'max_tags': 64,\n            'tag36h11_size': 0.16\n        }],\n        remappings=[\n            ('image', '/head_camera/image_rect'),\n            ('camera_info', '/head_camera/camera_info'),\n            ('detections', '/apriltag/detections'),\n        ]\n    )\n\n    # Isaac ROS Stereo DNN (for object detection)\n    stereo_dnn_node = Node(\n        package='isaac_ros_stereo_dnn',\n        executable='stereo_dnn_node',\n        name='stereo_dnn',\n        parameters=[{\n            'use_sim_time': use_sim_time,\n            'network_type': 'coco_tensorrt',\n            'input_tensor_names': ['input'],\n            'input_binding_names': ['input'],\n            'output_tensor_names': ['output'],\n            'output_binding_names': ['output'],\n            'threshold': 0.5\n        }],\n        remappings=[\n            ('left_image', '/stereo/left/image_rect'),\n            ('right_image', '/stereo/right/image_rect'),\n            ('detections', '/dnn_detections'),\n        ]\n    )\n\n    # Footstep planner\n    footstep_planner = Node(\n        package='humanoid_navigation_system',\n        executable='footstep_planner',\n        name='footstep_planner',\n        parameters=[{'use_sim_time': use_sim_time}],\n        remappings=[\n            ('/plan', '/plan'),\n            ('/footstep_plan', '/footstep_plan'),\n        ]\n    )\n\n    # Balance-aware planner\n    balance_planner = Node(\n        package='humanoid_navigation_system',\n        executable='balance_aware_planner',\n        name='balance_aware_planner',\n        parameters=[{'use_sim_time': use_sim_time}],\n        remappings=[\n            ('/plan', '/plan'),\n            ('/balance_aware_plan', '/balance_aware_plan'),\n        ]\n    )\n\n    # Stair navigation\n    stair_navigation = Node(\n        package='humanoid_navigation_system',\n        executable='stair_navigation',\n        name='stair_navigation',\n        parameters=[{'use_sim_time': use_sim_time}],\n        remappings=[\n            ('/scan', '/scan'),\n            ('/stair_navigation_plan', '/stair_navigation_plan'),\n        ]\n    )\n\n    # Humanoid navigation controller\n    humanoid_controller = Node(\n        package='humanoid_navigation_system',\n        executable='humanoid_navigation_controller',\n        name='humanoid_navigation_controller',\n        parameters=[{'use_sim_time': use_sim_time}],\n        remappings=[\n            ('/cmd_vel', '/cmd_vel'),\n            ('/footstep_plan', '/footstep_plan'),\n        ]\n    )\n\n    # AMCL localization\n    amcl = Node(\n        package='nav2_amcl',\n        executable='amcl',\n        name='amcl',\n        parameters=[params_file, {'use_sim_time': use_sim_time}],\n        remappings=[('scan', 'scan')]\n    )\n\n    # Map server\n    map_server = Node(\n        package='nav2_map_server',\n        executable='map_server',\n        name='map_server',\n        parameters=[params_file, {'use_sim_time': use_sim_time}],\n        remappings=[('map', 'map'),\n                   ('map_metadata', 'map_metadata')]\n    )\n\n    # Planner server\n    planner_server = Node(\n        package='nav2_planner',\n        executable='planner_server',\n        name='planner_server',\n        parameters=[params_file, {'use_sim_time': use_sim_time}],\n        remappings=[('~/global_costmap/costmap', 'global_costmap/costmap'),\n                   ('~/global_costmap/costmap_updates', 'global_costmap/costmap_updates')]\n    )\n\n    # Controller server\n    controller_server = Node(\n        package='nav2_controller',\n        executable='controller_server',\n        name='controller_server',\n        parameters=[params_file, {'use_sim_time': use_sim_time}],\n        remappings=[('cmd_vel', 'cmd_vel'),\n                   ('~/local_costmap/costmap', 'local_costmap/costmap'),\n                   ('~/local_costmap/costmap_updates', 'local_costmap/costmap_updates'),\n                   ('~/global_costmap/costmap', 'global_costmap/costmap')]\n    )\n\n    # Behavior server\n    behavior_server = Node(\n        package='nav2_behaviors',\n        executable='behavior_server',\n        name='behavior_server',\n        parameters=[params_file, {'use_sim_time': use_sim_time}],\n        remappings=[('cmd_vel', 'cmd_vel'),\n                   ('/local_costmap/costmap', '/local_costmap/costmap'),\n                   ('/local_costmap/costmap_updates', '/local_costmap/costmap_updates')]\n    )\n\n    # BT Navigator\n    bt_navigator = Node(\n        package='nav2_bt_navigator',\n        executable='bt_navigator',\n        name='bt_navigator',\n        parameters=[params_file, {'use_sim_time': use_sim_time}],\n        remappings=[('navigate_to_pose', 'navigate_to_pose'),\n                   ('navigate_through_poses', 'navigate_through_poses')]\n    )\n\n    # Lifecycle manager\n    lifecycle_manager = Node(\n        package='nav2_lifecycle_manager',\n        executable='lifecycle_manager',\n        name='lifecycle_manager',\n        output='screen',\n        parameters=[{'use_sim_time': use_sim_time},\n                    {'autostart': autostart},\n                    {'node_names': ['map_server',\n                                   'planner_server',\n                                   'controller_server',\n                                   'behavior_server',\n                                   'bt_navigator',\n                                   'amcl']}]\n    )\n\n    # Create groups for organized startup\n    perception_group = GroupAction(\n        actions=[\n            SetParameter('use_sim_time', use_sim_time),\n            vio_node,\n            apriltag_node,\n            stereo_dnn_node\n        ]\n    )\n\n    navigation_group = GroupAction(\n        actions=[\n            SetParameter('use_sim_time', use_sim_time),\n            amcl,\n            map_server,\n            planner_server,\n            controller_server,\n            behavior_server,\n            bt_navigator\n        ]\n    )\n\n    humanoid_group = GroupAction(\n        actions=[\n            SetParameter('use_sim_time', use_sim_time),\n            footstep_planner,\n            balance_planner,\n            stair_navigation,\n            humanoid_controller\n        ]\n    )\n\n    # Delayed lifecycle manager startup\n    delayed_lifecycle_manager = RegisterEventHandler(\n        OnProcessStart(\n            target_action=bt_navigator,\n            on_start=[lifecycle_manager]\n        )\n    )\n\n    return LaunchDescription([\n        declare_use_sim_time,\n        declare_autostart,\n        declare_params_file,\n        declare_robot_name,\n        declare_namespace,\n\n        robot_state_publisher,\n        *static_transforms,\n\n        perception_group,\n        navigation_group,\n        humanoid_group,\n\n        delayed_lifecycle_manager\n    ])\n"})}),"\n",(0,s.jsx)(n.h3,{id:"2-complete-system-configuration",children:"2. Complete System Configuration"}),"\n",(0,s.jsx)(n.p,{children:"Creating the comprehensive configuration file:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:'# config/complete_nav_params.yaml\namcl:\n  ros__parameters:\n    use_sim_time: True\n    alpha1: 0.2\n    alpha2: 0.2\n    alpha3: 0.2\n    alpha4: 0.2\n    alpha5: 0.2\n    base_frame_id: "base_link"\n    beam_skip_distance: 0.5\n    beam_skip_error_threshold: 0.9\n    beam_skip_threshold: 0.3\n    do_beamskip: false\n    global_frame_id: "map"\n    lambda_short: 0.1\n    laser_likelihood_max_dist: 2.0\n    laser_max_range: 100.0\n    laser_min_range: -1.0\n    laser_model_type: "likelihood_field"\n    max_beams: 60\n    max_particles: 2000\n    min_particles: 500\n    odom_frame_id: "odom"\n    pf_err: 0.05\n    pf_z: 0.99\n    recovery_alpha_fast: 0.0\n    recovery_alpha_slow: 0.0\n    resample_interval: 1\n    robot_model_type: "nav2_amcl::DifferentialMotionModel"\n    save_pose_rate: 0.5\n    sigma_hit: 0.2\n    tf_broadcast: true\n    transform_tolerance: 1.0\n    update_min_a: 0.2\n    update_min_d: 0.2\n    z_hit: 0.5\n    z_max: 0.05\n    z_rand: 0.5\n    z_short: 0.05\n\nbt_navigator:\n  ros__parameters:\n    use_sim_time: True\n    global_frame: "map"\n    robot_base_frame: "base_link"\n    odom_topic: "/odom"\n    bt_loop_duration: 10\n    default_server_timeout: 20\n    plugin_lib_names:\n    - nav2_compute_path_to_pose_action_bt_node\n    - nav2_follow_path_action_bt_node\n    - nav2_back_up_action_bt_node\n    - nav2_spin_action_bt_node\n    - nav2_wait_action_bt_node\n    - nav2_clear_costmap_service_bt_node\n    - nav2_is_stuck_condition_bt_node\n    - nav2_goal_reached_condition_bt_node\n    - nav2_goal_updated_condition_bt_node\n    - nav2_initial_pose_received_condition_bt_node\n    - nav2_reinitialize_global_localization_service_bt_node\n    - nav2_rate_controller_bt_node\n    - nav2_distance_controller_bt_node\n    - nav2_speed_controller_bt_node\n    - nav2_truncate_path_action_bt_node\n    - nav2_goal_updater_node_bt_node\n    - nav2_recovery_node_bt_node\n    - nav2_pipeline_sequence_bt_node\n    - nav2_round_robin_node_bt_node\n    - nav2_transform_available_condition_bt_node\n    - nav2_time_expired_condition_bt_node\n    - nav2_path_expiring_timer_condition\n    - nav2_distance_traveled_condition_bt_node\n    - nav2_single_trigger_bt_node\n    - nav2_is_battery_low_condition_bt_node\n    - nav2_navigate_through_poses_action_bt_node\n    - nav2_navigate_to_pose_action_bt_node\n    - nav2_remove_passed_goals_action_bt_node\n    - nav2_planner_selector_bt_node\n    - nav2_controller_selector_bt_node\n    - nav2_goal_checker_selector_bt_node\n    - nav2_controller_cancel_bt_node\n    - nav2_path_longer_on_approach_bt_node\n    - nav2_wait_cancel_bt_node\n\ncontroller_server:\n  ros__parameters:\n    use_sim_time: True\n    controller_frequency: 20.0\n    min_x_velocity_threshold: 0.001\n    min_y_velocity_threshold: 0.5\n    min_theta_velocity_threshold: 0.001\n    progress_checker_plugin: "progress_checker"\n    goal_checker_plugin: "goal_checker"\n    controller_plugins: ["FollowPath"]\n\n    FollowPath:\n      plugin: "nav2_mppi_controller::MPPIController"\n      time_steps: 50\n      model_dt: 0.05\n      batch_size: 1000\n      vx_std: 0.2\n      vy_std: 0.0\n      wz_std: 0.3\n      vx_max: 0.5\n      vx_min: -0.1\n      vy_max: 1.0\n      wz_max: 1.5\n      xy_goal_tolerance: 0.25\n      yaw_goal_tolerance: 0.25\n      state_reset_tolerance: 0.5\n      control_horizon: 10\n      trajectory_visualization_enabled: true\n      balance_weight: 10.0\n      step_size: 0.3\n      max_step_height: 0.15\n\n    progress_checker:\n      plugin: "nav2_controller::SimpleProgressChecker"\n      required_movement_radius: 0.5\n      movement_time_allowance: 10.0\n\n    goal_checker:\n      plugin: "nav2_controller::SimpleGoalChecker"\n      xy_goal_tolerance: 0.25\n      yaw_goal_tolerance: 0.25\n      state_tolerance: 0.05\n\nlocal_costmap:\n  local_costmap:\n    ros__parameters:\n      update_frequency: 5.0\n      publish_frequency: 2.0\n      global_frame: "odom"\n      robot_base_frame: "base_link"\n      use_sim_time: True\n      rolling_window: true\n      width: 6\n      height: 6\n      resolution: 0.05\n      robot_radius: 0.4\n      plugins: ["voxel_layer", "inflation_layer"]\n      inflation_layer:\n        plugin: "nav2_costmap_2d::InflationLayer"\n        cost_scaling_factor: 3.0\n        inflation_radius: 0.55\n      voxel_layer:\n        plugin: "nav2_costmap_2d::VoxelLayer"\n        enabled: True\n        publish_voxel_map: True\n        origin_z: 0.0\n        z_resolution: 0.2\n        z_voxels: 8\n        max_obstacle_height: 2.0\n        mark_threshold: 0\n        observation_sources: scan\n        scan:\n          topic: "/scan"\n          max_obstacle_height: 2.0\n          clearing: True\n          marking: True\n          data_type: "LaserScan"\n          raytrace_max_range: 3.0\n          raytrace_min_range: 0.0\n          obstacle_max_range: 2.5\n          obstacle_min_range: 0.0\n      static_layer:\n        plugin: "nav2_costmap_2d::StaticLayer"\n        map_subscribe_transient_local: True\n      always_send_full_costmap: True\n\nglobal_costmap:\n  global_costmap:\n    ros__parameters:\n      update_frequency: 1.0\n      publish_frequency: 1.0\n      global_frame: "map"\n      robot_base_frame: "base_link"\n      use_sim_time: True\n      robot_radius: 0.4\n      resolution: 0.05\n      track_unknown_space: true\n      plugins: ["static_layer", "obstacle_layer", "inflation_layer"]\n      obstacle_layer:\n        plugin: "nav2_costmap_2d::VoxelLayer"\n        enabled: True\n        publish_voxel_map: True\n        origin_z: 0.0\n        z_resolution: 0.2\n        z_voxels: 8\n        max_obstacle_height: 2.0\n        mark_threshold: 0\n        observation_sources: scan\n        scan:\n          topic: "/scan"\n          max_obstacle_height: 2.0\n          clearing: True\n          marking: True\n          data_type: "LaserScan"\n          raytrace_max_range: 3.0\n          raytrace_min_range: 0.0\n          obstacle_max_range: 2.5\n          obstacle_min_range: 0.0\n      static_layer:\n        plugin: "nav2_costmap_2d::StaticLayer"\n        map_subscribe_transient_local: True\n      inflation_layer:\n        plugin: "nav2_costmap_2d::InflationLayer"\n        cost_scaling_factor: 3.0\n        inflation_radius: 0.55\n\nplanner_server:\n  ros__parameters:\n    expected_planner_frequency: 20.0\n    use_sim_time: True\n    planner_plugins: ["GridBased"]\n    GridBased:\n      plugin: "nav2_navfn_planner::NavfnPlanner"\n      tolerance: 0.5\n      use_astar: false\n      allow_unknown: true\n'})}),"\n",(0,s.jsx)(n.h2,{id:"implementation-phase-2-system-validation",children:"Implementation Phase 2: System Validation"}),"\n",(0,s.jsx)(n.h3,{id:"1-system-validation-node",children:"1. System Validation Node"}),"\n",(0,s.jsx)(n.p,{children:"Creating a node to validate the complete system:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\n# system_validator.py\n\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image, Imu, LaserScan\nfrom nav_msgs.msg import Odometry, Path\nfrom geometry_msgs.msg import PoseStamped\nfrom std_msgs.msg import Bool, Float64\nfrom builtin_interfaces.msg import Time\nimport numpy as np\nimport time\nfrom collections import deque\n\nclass SystemValidator(Node):\n    \"\"\"\n    Validate the complete AI-powered humanoid navigation system\n    \"\"\"\n    def __init__(self):\n        super().__init__('system_validator')\n\n        # Subscribers for all system components\n        self.odom_sub = self.create_subscription(\n            Odometry,\n            '/odom',\n            self.odom_callback,\n            10\n        )\n\n        self.imu_sub = self.create_subscription(\n            Imu,\n            '/imu/data',\n            self.imu_callback,\n            10\n        )\n\n        self.scan_sub = self.create_subscription(\n            LaserScan,\n            '/scan',\n            self.scan_callback,\n            10\n        )\n\n        self.vio_sub = self.create_subscription(\n            Odometry,  # VIO typically outputs odometry\n            '/visual_odometry',\n            self.vio_callback,\n            10\n        )\n\n        self.path_sub = self.create_subscription(\n            Path,\n            '/plan',\n            self.path_callback,\n            10\n        )\n\n        self.footstep_sub = self.create_subscription(\n            Path,\n            '/footstep_plan',\n            self.footstep_callback,\n            10\n        )\n\n        # Publishers for validation results\n        self.validation_pub = self.create_publisher(\n            Bool,\n            '/system_validation_status',\n            10\n        )\n\n        self.performance_pub = self.create_publisher(\n            Float64,\n            '/system_performance_score',\n            10\n        )\n\n        # Validation tracking\n        self.odom_history = deque(maxlen=100)\n        self.vio_history = deque(maxlen=100)\n        self.scan_history = deque(maxlen=10)\n        self.path_history = deque(maxlen=10)\n        self.footstep_history = deque(maxlen=10)\n\n        # Performance metrics\n        self.start_time = time.time()\n        self.validation_results = {\n            'perception_valid': False,\n            'localization_valid': False,\n            'planning_valid': False,\n            'navigation_valid': False,\n            'balance_valid': False\n        }\n\n        # Validation thresholds\n        self.min_frequency_threshold = 10.0  # Hz\n        self.max_drift_threshold = 0.5  # meters\n        self.min_obstacle_detection = 0.8  # 80% detection rate\n\n        # Create timer for periodic validation\n        self.validation_timer = self.create_timer(1.0, self.run_validation)\n\n        self.get_logger().info('System Validator initialized')\n\n    def odom_callback(self, msg):\n        \"\"\"Track odometry data\"\"\"\n        self.odom_history.append({\n            'timestamp': msg.header.stamp,\n            'position': (msg.pose.pose.position.x, msg.pose.pose.position.y, msg.pose.pose.position.z),\n            'orientation': (msg.pose.pose.orientation.x, msg.pose.pose.orientation.y,\n                          msg.pose.pose.orientation.z, msg.pose.pose.orientation.w)\n        })\n\n    def imu_callback(self, msg):\n        \"\"\"Track IMU data for balance validation\"\"\"\n        # Store for balance validation\n        pass\n\n    def scan_callback(self, msg):\n        \"\"\"Track laser scan data\"\"\"\n        self.scan_history.append({\n            'timestamp': msg.header.stamp,\n            'ranges': np.array(msg.ranges),\n            'angle_min': msg.angle_min,\n            'angle_max': msg.angle_max,\n            'angle_increment': msg.angle_increment\n        })\n\n    def vio_callback(self, msg):\n        \"\"\"Track VIO data for localization validation\"\"\"\n        self.vio_history.append({\n            'timestamp': msg.header.stamp,\n            'position': (msg.pose.pose.position.x, msg.pose.pose.position.y, msg.pose.pose.position.z)\n        })\n\n    def path_callback(self, msg):\n        \"\"\"Track path planning results\"\"\"\n        self.path_history.append({\n            'timestamp': msg.header.stamp,\n            'waypoints': len(msg.poses)\n        })\n\n    def footstep_callback(self, msg):\n        \"\"\"Track footstep planning results\"\"\"\n        self.footstep_history.append({\n            'timestamp': msg.header.stamp,\n            'steps': len(msg.poses)\n        })\n\n    def run_validation(self):\n        \"\"\"\n        Run comprehensive system validation\n        \"\"\"\n        self.get_logger().info('Running system validation...')\n\n        # Validate perception system\n        self.validation_results['perception_valid'] = self.validate_perception()\n\n        # Validate localization system\n        self.validation_results['localization_valid'] = self.validate_localization()\n\n        # Validate planning system\n        self.validation_results['planning_valid'] = self.validate_planning()\n\n        # Validate navigation system\n        self.validation_results['navigation_valid'] = self.validate_navigation()\n\n        # Validate balance system\n        self.validation_results['balance_valid'] = self.validate_balance()\n\n        # Calculate overall performance score\n        performance_score = self.calculate_performance_score()\n\n        # Publish validation results\n        validation_msg = Bool()\n        validation_msg.data = all(self.validation_results.values())\n        self.validation_pub.publish(validation_msg)\n\n        performance_msg = Float64()\n        performance_msg.data = performance_score\n        self.performance_pub.publish(performance_msg)\n\n        # Log validation results\n        self.log_validation_results()\n\n    def validate_perception(self):\n        \"\"\"\n        Validate perception system performance\n        \"\"\"\n        if len(self.scan_history) == 0:\n            return False\n\n        # Check if scan data is being received at expected rate\n        if len(self.scan_history) < 10:  # Should have at least 10 scans in 10 seconds at 1Hz\n            self.get_logger().warn('Perception: Low scan frequency')\n            return False\n\n        # Check for obstacle detection\n        recent_scans = list(self.scan_history)[-5:]  # Last 5 scans\n        obstacle_detections = 0\n        total_ranges = 0\n\n        for scan in recent_scans:\n            valid_ranges = scan['ranges'][np.isfinite(scan['ranges'])]\n            obstacles = valid_ranges[valid_ranges < 2.0]  # Obstacles within 2m\n            obstacle_detections += len(obstacles)\n            total_ranges += len(valid_ranges)\n\n        detection_rate = obstacle_detections / total_ranges if total_ranges > 0 else 0\n        if detection_rate < self.min_obstacle_detection:\n            self.get_logger().warn(f'Perception: Low obstacle detection rate: {detection_rate:.2f}')\n            return False\n\n        self.get_logger().info(f'Perception validation passed: {detection_rate:.2f} detection rate')\n        return True\n\n    def validate_localization(self):\n        \"\"\"\n        Validate localization system performance\n        \"\"\"\n        if len(self.odom_history) < 2 or len(self.vio_history) < 2:\n            return False\n\n        # Calculate drift between odometry and VIO\n        odom_pos = self.odom_history[-1]['position']\n        vio_pos = self.vio_history[-1]['position']\n\n        drift = np.sqrt(\n            (odom_pos[0] - vio_pos[0])**2 +\n            (odom_pos[1] - vio_pos[1])**2 +\n            (odom_pos[2] - vio_pos[2])**2\n        )\n\n        if drift > self.max_drift_threshold:\n            self.get_logger().warn(f'Localization: High drift detected: {drift:.2f}m')\n            return False\n\n        self.get_logger().info(f'Localization validation passed: {drift:.2f}m drift')\n        return True\n\n    def validate_planning(self):\n        \"\"\"\n        Validate path planning performance\n        \"\"\"\n        if len(self.path_history) == 0:\n            return False\n\n        # Check if paths are being generated\n        recent_paths = list(self.path_history)[-5:]  # Last 5 path updates\n        if len(recent_paths) == 0:\n            self.get_logger().warn('Planning: No paths generated recently')\n            return False\n\n        # Check path quality (simplified)\n        avg_waypoints = np.mean([p['waypoints'] for p in recent_paths])\n        if avg_waypoints < 2:  # Need at least 2 waypoints for a valid path\n            self.get_logger().warn(f'Planning: Low average waypoints: {avg_waypoints:.1f}')\n            return False\n\n        self.get_logger().info(f'Planning validation passed: {avg_waypoints:.1f} avg waypoints')\n        return True\n\n    def validate_navigation(self):\n        \"\"\"\n        Validate navigation system performance\n        \"\"\"\n        if len(self.footstep_history) == 0:\n            return False\n\n        # Check if footsteps are being planned\n        recent_footsteps = list(self.footstep_history)[-5:]\n        if len(recent_footsteps) == 0:\n            self.get_logger().warn('Navigation: No footsteps planned recently')\n            return False\n\n        # Check footstep quality\n        avg_steps = np.mean([f['steps'] for f in recent_footsteps])\n        if avg_steps < 1:  # Need at least 1 step to navigate\n            self.get_logger().warn(f'Navigation: Low average steps: {avg_steps:.1f}')\n            return False\n\n        self.get_logger().info(f'Navigation validation passed: {avg_steps:.1f} avg steps')\n        return True\n\n    def validate_balance(self):\n        \"\"\"\n        Validate balance system performance\n        \"\"\"\n        # This would check IMU data for balance metrics\n        # For now, we'll assume balance is maintained if system is running\n        return True\n\n    def calculate_performance_score(self):\n        \"\"\"\n        Calculate overall system performance score\n        \"\"\"\n        score = sum(self.validation_results.values()) / len(self.validation_results)\n        return score\n\n    def log_validation_results(self):\n        \"\"\"\n        Log validation results in a readable format\n        \"\"\"\n        self.get_logger().info('=== SYSTEM VALIDATION RESULTS ===')\n        for component, valid in self.validation_results.items():\n            status = '\u2713 PASS' if valid else '\u2717 FAIL'\n            self.get_logger().info(f'{component}: {status}')\n\n        total_score = self.calculate_performance_score()\n        self.get_logger().info(f'Overall Performance Score: {total_score:.2f}/1.0')\n        self.get_logger().info('=================================')\n\ndef main(args=None):\n    rclpy.init(args=args)\n    validator = SystemValidator()\n\n    try:\n        rclpy.spin(validator)\n    except KeyboardInterrupt:\n        validator.get_logger().info('Shutting down system validator')\n    finally:\n        validator.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,s.jsx)(n.h2,{id:"implementation-phase-3-performance-optimization",children:"Implementation Phase 3: Performance Optimization"}),"\n",(0,s.jsx)(n.h3,{id:"1-system-performance-monitor",children:"1. System Performance Monitor"}),"\n",(0,s.jsx)(n.p,{children:"Creating a performance monitoring system:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\n# performance_monitor.py\n\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image, Imu, LaserScan\nfrom std_msgs.msg import Float64, String\nfrom builtin_interfaces.msg import Time\nimport time\nfrom collections import deque\nimport psutil\nimport GPUtil\n\nclass PerformanceMonitor(Node):\n    \"\"\"\n    Monitor performance of the complete humanoid navigation system\n    \"\"\"\n    def __init__(self):\n        super().__init__('performance_monitor')\n\n        # Performance tracking\n        self.cpu_percentages = deque(maxlen=100)\n        self.memory_percentages = deque(maxlen=100)\n        self.gpu_loads = deque(maxlen=100)\n        self.process_times = deque(maxlen=100)\n\n        # Publishers for performance metrics\n        self.cpu_pub = self.create_publisher(Float64, '/performance/cpu_usage', 10)\n        self.memory_pub = self.create_publisher(Float64, '/performance/memory_usage', 10)\n        self.gpu_pub = self.create_publisher(Float64, '/performance/gpu_usage', 10)\n        self.process_time_pub = self.create_publisher(Float64, '/performance/process_time', 10)\n        self.system_status_pub = self.create_publisher(String, '/performance/system_status', 10)\n\n        # Create timer for performance monitoring\n        self.monitor_timer = self.create_timer(0.1, self.monitor_performance)  # 10Hz\n\n        # Performance thresholds\n        self.cpu_threshold = 80.0  # 80% CPU usage\n        self.memory_threshold = 85.0  # 85% memory usage\n        self.gpu_threshold = 85.0  # 85% GPU usage\n\n        self.get_logger().info('Performance Monitor initialized')\n\n    def monitor_performance(self):\n        \"\"\"\n        Monitor system performance metrics\n        \"\"\"\n        # CPU usage\n        cpu_percent = psutil.cpu_percent()\n        self.cpu_percentages.append(cpu_percent)\n\n        # Memory usage\n        memory_percent = psutil.virtual_memory().percent\n        self.memory_percentages.append(memory_percent)\n\n        # GPU usage (if available)\n        gpu_load = 0.0\n        gpus = GPUtil.getGPUs()\n        if gpus:\n            gpu_load = gpus[0].load * 100  # Convert to percentage\n        self.gpu_loads.append(gpu_load)\n\n        # Publish metrics\n        cpu_msg = Float64()\n        cpu_msg.data = float(cpu_percent)\n        self.cpu_pub.publish(cpu_msg)\n\n        memory_msg = Float64()\n        memory_msg.data = float(memory_percent)\n        self.memory_pub.publish(memory_msg)\n\n        gpu_msg = Float64()\n        gpu_msg.data = float(gpu_load)\n        self.gpu_pub.publish(gpu_msg)\n\n        # Determine system status\n        status_msg = String()\n        if (cpu_percent > self.cpu_threshold or\n            memory_percent > self.memory_threshold or\n            gpu_load > self.gpu_threshold):\n            status_msg.data = \"OVERLOADED\"\n        elif (cpu_percent > self.cpu_threshold * 0.7 or\n              memory_percent > self.memory_threshold * 0.7 or\n              gpu_load > self.gpu_threshold * 0.7):\n            status_msg.data = \"HEAVY_LOAD\"\n        else:\n            status_msg.data = \"NORMAL\"\n\n        self.system_status_pub.publish(status_msg)\n\n        # Log warnings if thresholds exceeded\n        if cpu_percent > self.cpu_threshold:\n            self.get_logger().warn(f'High CPU usage: {cpu_percent:.1f}%')\n        if memory_percent > self.memory_threshold:\n            self.get_logger().warn(f'High memory usage: {memory_percent:.1f}%')\n        if gpu_load > self.gpu_threshold:\n            self.get_logger().warn(f'High GPU usage: {gpu_load:.1f}%')\n\n        # Log performance summary periodically\n        if len(self.cpu_percentages) % 50 == 0:  # Every 5 seconds at 10Hz\n            avg_cpu = sum(self.cpu_percentages) / len(self.cpu_percentages)\n            avg_memory = sum(self.memory_percentages) / len(self.memory_percentages)\n            avg_gpu = sum(self.gpu_loads) / len(self.gpu_loads) if self.gpu_loads else 0.0\n\n            self.get_logger().info(\n                f'Performance Summary - CPU: {avg_cpu:.1f}%, '\n                f'Memory: {avg_memory:.1f}%, GPU: {avg_gpu:.1f}%'\n            )\n\ndef main(args=None):\n    rclpy.init(args=args)\n    monitor = PerformanceMonitor()\n\n    try:\n        rclpy.spin(monitor)\n    except KeyboardInterrupt:\n        monitor.get_logger().info('Shutting down performance monitor')\n    finally:\n        monitor.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,s.jsx)(n.h2,{id:"implementation-phase-4-testing-and-demonstration",children:"Implementation Phase 4: Testing and Demonstration"}),"\n",(0,s.jsx)(n.h3,{id:"1-navigation-test-scenarios",children:"1. Navigation Test Scenarios"}),"\n",(0,s.jsx)(n.p,{children:"Creating test scenarios to demonstrate the complete system:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'#!/usr/bin/env python3\n# navigation_test_scenarios.py\n\nimport rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import PoseStamped, Point\nfrom nav_msgs.msg import Path\nfrom std_msgs.msg import String, Bool\nfrom builtin_interfaces.msg import Duration\nimport time\nimport math\n\nclass NavigationTestScenarios(Node):\n    """\n    Test scenarios for the complete AI-powered humanoid navigation system\n    """\n    def __init__(self):\n        super().__init__(\'navigation_test_scenarios\')\n\n        # Publishers\n        self.goal_pub = self.create_publisher(PoseStamped, \'/goal_pose\', 10)\n        self.test_status_pub = self.create_publisher(String, \'/test_status\', 10)\n        self.test_result_pub = self.create_publisher(Bool, \'/test_result\', 10)\n\n        # Test control\n        self.test_active = False\n        self.current_test = 0\n        self.test_results = []\n\n        # Create timer for test execution\n        self.test_timer = self.create_timer(5.0, self.execute_next_test)\n\n        self.get_logger().info(\'Navigation Test Scenarios initialized\')\n\n    def execute_next_test(self):\n        """\n        Execute the next navigation test scenario\n        """\n        if self.test_active:\n            return  # Wait for current test to complete\n\n        test_scenarios = [\n            self.test_simple_navigation,\n            self.test_obstacle_avoidance,\n            self.test_dynamic_obstacles,\n            self.test_stair_navigation,\n            self.test_multi_floor_navigation\n        ]\n\n        if self.current_test < len(test_scenarios):\n            self.get_logger().info(f\'Executing test {self.current_test + 1}: {test_scenarios[self.current_test].__name__}\')\n            self.test_active = True\n            test_scenarios[self.current_test]()\n            self.current_test += 1\n        else:\n            self.get_logger().info(\'All navigation tests completed\')\n            self.publish_test_summary()\n\n    def test_simple_navigation(self):\n        """\n        Test 1: Simple point-to-point navigation\n        """\n        goal = PoseStamped()\n        goal.header.stamp = self.get_clock().now().to_msg()\n        goal.header.frame_id = \'map\'\n        goal.pose.position.x = 5.0\n        goal.pose.position.y = 3.0\n        goal.pose.position.z = 0.0\n        goal.pose.orientation.w = 1.0\n\n        self.goal_pub.publish(goal)\n\n        # Wait for navigation to complete (simplified)\n        time.sleep(10)  # Wait for navigation to potentially complete\n        self.test_active = False\n\n        # In a real implementation, you\'d check if navigation was successful\n        result = Bool()\n        result.data = True  # Assume success for this example\n        self.test_result_pub.publish(result)\n\n    def test_obstacle_avoidance(self):\n        """\n        Test 2: Navigation with static obstacle avoidance\n        """\n        goal = PoseStamped()\n        goal.header.stamp = self.get_clock().now().to_msg()\n        goal.header.frame_id = \'map\'\n        goal.pose.position.x = 8.0\n        goal.pose.position.y = -2.0\n        goal.pose.position.z = 0.0\n        goal.pose.orientation.w = 1.0\n\n        self.goal_pub.publish(goal)\n\n        # Wait for navigation to complete\n        time.sleep(15)\n        self.test_active = False\n\n        result = Bool()\n        result.data = True\n        self.test_result_pub.publish(result)\n\n    def test_dynamic_obstacles(self):\n        """\n        Test 3: Navigation with dynamic obstacle avoidance\n        """\n        goal = PoseStamped()\n        goal.header.stamp = self.get_clock().now().to_msg()\n        goal.header.frame_id = \'map\'\n        goal.pose.position.x = -3.0\n        goal.pose.position.y = 5.0\n        goal.pose.position.z = 0.0\n        goal.pose.orientation.w = 1.0\n\n        self.goal_pub.publish(goal)\n\n        # Wait for navigation to complete\n        time.sleep(20)\n        self.test_active = False\n\n        result = Bool()\n        result.data = True\n        self.test_result_pub.publish(result)\n\n    def test_stair_navigation(self):\n        """\n        Test 4: Navigation involving stairs\n        """\n        goal = PoseStamped()\n        goal.header.stamp = self.get_clock().now().to_msg()\n        goal.header.frame_id = \'map\'\n        goal.pose.position.x = 0.0\n        goal.pose.position.y = 8.0\n        goal.pose.position.z = 1.0  # Higher floor\n        goal.pose.orientation.w = 1.0\n\n        self.goal_pub.publish(goal)\n\n        # Wait for navigation to complete\n        time.sleep(25)\n        self.test_active = False\n\n        result = Bool()\n        result.data = True\n        self.test_result_pub.publish(result)\n\n    def test_multi_floor_navigation(self):\n        """\n        Test 5: Multi-floor navigation\n        """\n        goal = PoseStamped()\n        goal.header.stamp = self.get_clock().now().to_msg()\n        goal.header.frame_id = \'map\'\n        goal.pose.position.x = -5.0\n        goal.pose.position.y = -5.0\n        goal.pose.position.z = 2.0  # Even higher floor\n        goal.pose.orientation.w = 1.0\n\n        self.goal_pub.publish(goal)\n\n        # Wait for navigation to complete\n        time.sleep(30)\n        self.test_active = False\n\n        result = Bool()\n        result.data = True\n        self.test_result_pub.publish(result)\n\n    def publish_test_summary(self):\n        """\n        Publish summary of all test results\n        """\n        success_count = sum(self.test_results)\n        total_tests = len(self.test_results)\n\n        summary = f\'Navigation Test Summary: {success_count}/{total_tests} tests passed\'\n        self.get_logger().info(summary)\n\n        status_msg = String()\n        status_msg.data = summary\n        self.test_status_pub.publish(status_msg)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    test_scenarios = NavigationTestScenarios()\n\n    try:\n        rclpy.spin(test_scenarios)\n    except KeyboardInterrupt:\n        test_scenarios.get_logger().info(\'Shutting down navigation test scenarios\')\n    finally:\n        test_scenarios.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == \'__main__\':\n    main()\n'})}),"\n",(0,s.jsx)(n.h2,{id:"performance-metrics-and-evaluation",children:"Performance Metrics and Evaluation"}),"\n",(0,s.jsx)(n.h3,{id:"1-comprehensive-performance-evaluation",children:"1. Comprehensive Performance Evaluation"}),"\n",(0,s.jsx)(n.p,{children:"Evaluating the complete system's performance:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"# performance_evaluation.md\n\n## Performance Evaluation of AI-Powered Humanoid Navigation System\n\n### 1. Navigation Performance Metrics\n\n#### Success Rate\n- **Metric**: Percentage of successful navigation attempts\n- **Target**: >95% success rate in static environments\n- **Measurement**: Number of successful navigations / Total navigation attempts\n\n#### Navigation Time\n- **Metric**: Time taken to reach goal from start\n- **Target**: Within 10% of optimal path time\n- **Measurement**: Elapsed time from navigation start to goal reached\n\n#### Path Efficiency\n- **Metric**: Actual path length vs. optimal path length\n- **Target**: Path efficiency > 0.9 (actual path \u2264 1.1 \xd7 optimal path)\n- **Measurement**: (Optimal distance / Actual distance) \xd7 100%\n\n#### Localization Accuracy\n- **Metric**: Position error compared to ground truth\n- **Target**: <0.1m position error in static environments\n- **Measurement**: Euclidean distance between estimated and actual position\n\n### 2. Perception Performance Metrics\n\n#### Detection Rate\n- **Metric**: Percentage of objects correctly detected\n- **Target**: >90% detection rate for obstacles >0.2m\n- **Measurement**: (Detected objects / Total objects) \xd7 100%\n\n#### False Positive Rate\n- **Metric**: Percentage of non-objects incorrectly detected\n- **Target**: <5% false positive rate\n- **Measurement**: (False detections / Total detections) \xd7 100%\n\n#### Processing Latency\n- **Metric**: Time from sensor input to processed output\n- **Target**: <50ms processing latency\n- **Measurement**: Average time from sensor data arrival to result publication\n\n### 3. System Performance Metrics\n\n#### CPU Utilization\n- **Target**: <70% average CPU utilization\n- **Measurement**: Average percentage of CPU usage across all processes\n\n#### Memory Usage\n- **Target**: <80% memory utilization\n- **Measurement**: Average percentage of memory usage\n\n#### GPU Utilization\n- **Target**: <85% GPU utilization for perception tasks\n- **Measurement**: Average percentage of GPU usage for Isaac ROS processes\n\n#### Real-time Performance\n- **Target**: >95% of processes meeting timing constraints\n- **Measurement**: Percentage of control cycles completing within deadline\n\n### 4. Balance and Stability Metrics\n\n#### Balance Maintenance\n- **Metric**: Percentage of time robot maintains balance\n- **Target**: >98% balance maintenance during navigation\n- **Measurement**: Time in balanced state / Total navigation time\n\n#### Step Success Rate\n- **Metric**: Percentage of successful foot placements\n- **Target**: >99% successful steps\n- **Measurement**: (Successful steps / Total steps) \xd7 100%\n\n#### Gait Stability\n- **Metric**: Variance in walking pattern\n- **Target**: Low variance in step timing and placement\n- **Measurement**: Standard deviation of step parameters\n\n### 5. Evaluation Methodology\n\n#### Testing Environments\n1. **Simple Corridor**: Basic navigation test\n2. **Cluttered Room**: Obstacle avoidance test\n3. **Multi-room Layout**: Path planning test\n4. **Stair Environment**: Complex terrain test\n5. **Dynamic Obstacles**: Real-time adaptation test\n\n#### Data Collection\n- Record all sensor data, commands, and states\n- Log performance metrics continuously\n- Capture video of navigation for qualitative analysis\n- Store system states for post-processing analysis\n\n#### Statistical Analysis\n- Run each test scenario 30+ times for statistical significance\n- Calculate mean, median, and standard deviation\n- Perform confidence interval analysis\n- Identify outlier cases and root causes\n"})}),"\n",(0,s.jsx)(n.h2,{id:"troubleshooting-guide",children:"Troubleshooting Guide"}),"\n",(0,s.jsx)(n.h3,{id:"1-common-issues-and-solutions",children:"1. Common Issues and Solutions"}),"\n",(0,s.jsx)(n.h4,{id:"localization-issues",children:"Localization Issues"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Problem"}),": Robot loses localization frequently\n",(0,s.jsx)(n.strong,{children:"Solutions"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Check camera calibration and lighting conditions"}),"\n",(0,s.jsx)(n.li,{children:"Verify IMU is properly calibrated"}),"\n",(0,s.jsx)(n.li,{children:"Increase VIO tracking features"}),"\n",(0,s.jsx)(n.li,{children:"Ensure sufficient visual features in environment"}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"navigation-failures",children:"Navigation Failures"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Problem"}),": Robot fails to navigate to goal\n",(0,s.jsx)(n.strong,{children:"Solutions"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Verify costmap inflation parameters"}),"\n",(0,s.jsx)(n.li,{children:"Check footstep planning constraints"}),"\n",(0,s.jsx)(n.li,{children:"Ensure balance constraints are not too restrictive"}),"\n",(0,s.jsx)(n.li,{children:"Validate path planner parameters"}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"performance-issues",children:"Performance Issues"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Problem"}),": System runs slowly or misses deadlines\n",(0,s.jsx)(n.strong,{children:"Solutions"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Optimize Isaac ROS pipeline for GPU usage"}),"\n",(0,s.jsx)(n.li,{children:"Reduce sensor data resolution where possible"}),"\n",(0,s.jsx)(n.li,{children:"Implement multi-threading for perception tasks"}),"\n",(0,s.jsx)(n.li,{children:"Profile and optimize critical code paths"}),"\n"]}),"\n",(0,s.jsx)(n.h4,{id:"balance-problems",children:"Balance Problems"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Problem"}),": Robot falls during navigation\n",(0,s.jsx)(n.strong,{children:"Solutions"}),":"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Adjust step size and timing parameters"}),"\n",(0,s.jsx)(n.li,{children:"Improve balance control algorithms"}),"\n",(0,s.jsx)(n.li,{children:"Verify IMU and joint feedback accuracy"}),"\n",(0,s.jsx)(n.li,{children:"Implement safety fallback behaviors"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsx)(n.p,{children:"With the complete AI-powered humanoid navigation system implemented and validated, you're now ready to move on to Module 4: Vision-Language-Action (VLA). Module 4 will cover implementing voice-to-action systems using OpenAI Whisper, cognitive planning using LLMs, and integrating perception, planning, and manipulation for humanoid robots."}),"\n",(0,s.jsx)(n.p,{children:"The system you've built in Module 3 provides the foundation for intelligent navigation that will be essential when implementing the higher-level cognitive functions in Module 4."})]})}function m(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(_,{...e})}):_(e)}},8453:(e,n,a)=>{a.d(n,{R:()=>i,x:()=>r});var t=a(6540);const s={},o=t.createContext(s);function i(e){const n=t.useContext(o);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),t.createElement(o.Provider,{value:n},e.children)}}}]);