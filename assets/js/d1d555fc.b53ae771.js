"use strict";(globalThis.webpackChunkmy_website=globalThis.webpackChunkmy_website||[]).push([[2508],{6235:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>l,contentTitle:()=>t,default:()=>c,frontMatter:()=>r,metadata:()=>i,toc:()=>m});const i=JSON.parse('{"id":"module-2-digital-twin/gazebo-simulation/sensor-simulation","title":"Sensor Simulation in Gazebo","description":"Overview","source":"@site/docs/module-2-digital-twin/gazebo-simulation/sensor-simulation.md","sourceDirName":"module-2-digital-twin/gazebo-simulation","slug":"/module-2-digital-twin/gazebo-simulation/sensor-simulation","permalink":"/hackathon_textbook_ai_robotics/docs/module-2-digital-twin/gazebo-simulation/sensor-simulation","draft":false,"unlisted":false,"editUrl":"https://github.com/Jiyakhan321/hackathon_textbook_ai_robotics/tree/main/docs/module-2-digital-twin/gazebo-simulation/sensor-simulation.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"sidebar_position":6},"sidebar":"tutorialSidebar","previous":{"title":"Gazebo-ROS Integration","permalink":"/hackathon_textbook_ai_robotics/docs/module-2-digital-twin/gazebo-simulation/gazebo-ros-integration"},"next":{"title":"Unity Robotics Setup and Configuration","permalink":"/hackathon_textbook_ai_robotics/docs/module-2-digital-twin/unity-simulation/unity-robotics-setup"}}');var s=a(4848),o=a(8453);const r={sidebar_position:6},t="Sensor Simulation in Gazebo",l={},m=[{value:"Overview",id:"overview",level:2},{value:"Camera Sensor Simulation",id:"camera-sensor-simulation",level:2},{value:"1. Basic Camera Configuration",id:"1-basic-camera-configuration",level:3},{value:"2. Depth Camera Configuration",id:"2-depth-camera-configuration",level:3},{value:"3. Stereo Camera Setup",id:"3-stereo-camera-setup",level:3},{value:"LiDAR Sensor Simulation",id:"lidar-sensor-simulation",level:2},{value:"1. 2D LiDAR Configuration",id:"1-2d-lidar-configuration",level:3},{value:"2. 3D LiDAR Configuration",id:"2-3d-lidar-configuration",level:3},{value:"3. Multi-Beam LiDAR",id:"3-multi-beam-lidar",level:3},{value:"IMU Sensor Simulation",id:"imu-sensor-simulation",level:2},{value:"1. Basic IMU Configuration",id:"1-basic-imu-configuration",level:3},{value:"2. Advanced IMU with Magnetometer",id:"2-advanced-imu-with-magnetometer",level:3},{value:"Force/Torque Sensor Simulation",id:"forcetorque-sensor-simulation",level:2},{value:"1. Joint Force/Torque Sensors",id:"1-joint-forcetorque-sensors",level:3},{value:"2. Six-Axis Force/Torque Sensor",id:"2-six-axis-forcetorque-sensor",level:3},{value:"GPS Sensor Simulation",id:"gps-sensor-simulation",level:2},{value:"1. GPS Configuration for Outdoor Navigation",id:"1-gps-configuration-for-outdoor-navigation",level:3},{value:"Sensor Fusion and Data Processing",id:"sensor-fusion-and-data-processing",level:2},{value:"1. Robot State Publisher Integration",id:"1-robot-state-publisher-integration",level:3},{value:"2. Sensor Data Aggregation",id:"2-sensor-data-aggregation",level:3},{value:"Sensor Performance Optimization",id:"sensor-performance-optimization",level:2},{value:"1. Efficient Sensor Configuration",id:"1-efficient-sensor-configuration",level:3},{value:"2. Sensor Scheduling and Threading",id:"2-sensor-scheduling-and-threading",level:3},{value:"Sensor Validation and Testing",id:"sensor-validation-and-testing",level:2},{value:"1. Sensor Data Validation",id:"1-sensor-data-validation",level:3},{value:"Troubleshooting Common Sensor Issues",id:"troubleshooting-common-sensor-issues",level:2},{value:"1. Sensor Data Quality Issues",id:"1-sensor-data-quality-issues",level:3},{value:"2. Performance Issues",id:"2-performance-issues",level:3},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"sensor-simulation-in-gazebo",children:"Sensor Simulation in Gazebo"})}),"\n",(0,s.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsx)(n.p,{children:"Sensor simulation in Gazebo is fundamental to creating realistic digital twin environments for humanoid robots. Proper sensor configuration enables accurate perception, navigation, and interaction with the virtual world. This section covers the implementation of various sensors in Gazebo, including cameras, LiDAR, IMU, and force/torque sensors with proper ROS 2 integration."}),"\n",(0,s.jsx)(n.h2,{id:"camera-sensor-simulation",children:"Camera Sensor Simulation"}),"\n",(0,s.jsx)(n.h3,{id:"1-basic-camera-configuration",children:"1. Basic Camera Configuration"}),"\n",(0,s.jsx)(n.p,{children:"Setting up realistic camera sensors in Gazebo involves configuring the camera plugin with appropriate parameters:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-xml",children:'<?xml version="1.0" ?>\n<sdf version="1.7">\n  <model name="humanoid_with_camera">\n    <link name="head_link">\n      <pose>0 0 1.7 0 0 0</pose>\n\n      \x3c!-- Camera sensor configuration --\x3e\n      <sensor name="camera_sensor" type="camera">\n        <pose>0.1 0 0 0 0 0</pose> \x3c!-- Offset from head center --\x3e\n        <camera name="head_camera">\n          \x3c!-- Image settings --\x3e\n          <image>\n            <width>640</width>\n            <height>480</height>\n            <format>R8G8B8</format>\n          </image>\n\n          \x3c!-- Camera intrinsics --\x3e\n          <intrinsics>\n            <fx>320</fx> \x3c!-- Focal length in x --\x3e\n            <fy>320</fy> \x3c!-- Focal length in y --\x3e\n            <cx>320</cx> \x3c!-- Principal point x --\x3e\n            <cy>240</cy> \x3c!-- Principal point y --\x3e\n            <s>0</s>     \x3c!-- Skew --\x3e\n          </intrinsics>\n\n          \x3c!-- Distortion parameters --\x3e\n          <distortion>\n            <k1>0.0</k1>\n            <k2>0.0</k2>\n            <k3>0.0</k3>\n            <p1>0.0</p1>\n            <p2>0.0</p2>\n            <center>0.5 0.5</center>\n          </distortion>\n\n          \x3c!-- View settings --\x3e\n          <horizontal_fov>1.0472</horizontal_fov> \x3c!-- 60 degrees in radians --\x3e\n          <clip>\n            <near>0.1</near>\n            <far>10.0</far>\n          </clip>\n        </camera>\n\n        \x3c!-- Camera plugin for ROS 2 communication --\x3e\n        <plugin name="camera_controller" filename="libgazebo_ros_camera.so">\n          <frame_name>head_camera_frame</frame_name>\n          <topic_name>/camera/image_raw</topic_name>\n          <camera_info_topic_name>/camera/camera_info</camera_info_topic_name>\n          <hack_baseline>0.07</hack_baseline>\n          <distortion_k1>0.0</distortion_k1>\n          <distortion_k2>0.0</distortion_k2>\n          <distortion_k3>0.0</distortion_k3>\n          <distortion_t1>0.0</distortion_t1>\n          <distortion_t2>0.0</distortion_t2>\n        </plugin>\n      </sensor>\n    </link>\n  </model>\n</sdf>\n'})}),"\n",(0,s.jsx)(n.h3,{id:"2-depth-camera-configuration",children:"2. Depth Camera Configuration"}),"\n",(0,s.jsx)(n.p,{children:"For 3D perception and depth estimation:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-xml",children:'<sensor name="depth_camera" type="depth">\n  <pose>0.1 0 0.05 0 0 0</pose> \x3c!-- Slightly above regular camera --\x3e\n  <camera name="head_depth_camera">\n    <image>\n      <width>640</width>\n      <height>480</height>\n      <format>R8G8B8</format>\n    </image>\n\n    <depth_camera>\n      <output>depths</output>\n    </depth_camera>\n\n    <horizontal_fov>1.0472</horizontal_fov> \x3c!-- 60 degrees --\x3e\n    <clip>\n      <near>0.1</near>\n      <far>5.0</far>\n    </clip>\n  </camera>\n\n  <plugin name="depth_camera_controller" filename="libgazebo_ros_depth_camera.so">\n    <frame_name>head_depth_camera_frame</frame_name>\n    <topic_name>/camera/depth/image_raw</topic_name>\n    <camera_info_topic_name>/camera/depth/camera_info</camera_info_topic_name>\n    <point_cloud_topic_name>/camera/depth/points</point_cloud_topic_name>\n    <depth_image_topic_name>/camera/depth/image</depth_image_topic_name>\n    <min_depth>0.1</min_depth>\n    <max_depth>5.0</max_depth>\n    <point_cloud_cutoff>0.1</point_cloud_cutoff>\n    <point_cloud_cutoff_max>5.0</point_cloud_cutoff_max>\n  </plugin>\n</sensor>\n'})}),"\n",(0,s.jsx)(n.h3,{id:"3-stereo-camera-setup",children:"3. Stereo Camera Setup"}),"\n",(0,s.jsx)(n.p,{children:"For binocular vision and depth perception:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-xml",children:'<sensor name="stereo_camera_left" type="camera">\n  <pose>-0.032 0 0 0 0 0</pose> \x3c!-- Left of center --\x3e\n  <camera name="left_camera">\n    <image>\n      <width>640</width>\n      <height>480</height>\n      <format>R8G8B8</format>\n    </image>\n    <horizontal_fov>1.0472</horizontal_fov>\n    <clip>\n      <near>0.1</near>\n      <far>10.0</far>\n    </clip>\n  </camera>\n\n  <plugin name="left_camera_controller" filename="libgazebo_ros_camera.so">\n    <frame_name>left_camera_frame</frame_name>\n    <topic_name>/stereo/left/image_raw</topic_name>\n    <camera_info_topic_name>/stereo/left/camera_info</camera_info_topic_name>\n  </plugin>\n</sensor>\n\n<sensor name="stereo_camera_right" type="camera">\n  <pose>0.032 0 0 0 0 0</pose> \x3c!-- Right of center --\x3e\n  <camera name="right_camera">\n    <image>\n      <width>640</width>\n      <height>480</height>\n      <format>R8G8B8</format>\n    </image>\n    <horizontal_fov>1.0472</horizontal_fov>\n    <clip>\n      <near>0.1</near>\n      <far>10.0</far>\n    </clip>\n  </camera>\n\n  <plugin name="right_camera_controller" filename="libgazebo_ros_camera.so">\n    <frame_name>right_camera_frame</frame_name>\n    <topic_name>/stereo/right/image_raw</topic_name>\n    <camera_info_topic_name>/stereo/right/camera_info</camera_info_topic_name>\n  </plugin>\n</sensor>\n'})}),"\n",(0,s.jsx)(n.h2,{id:"lidar-sensor-simulation",children:"LiDAR Sensor Simulation"}),"\n",(0,s.jsx)(n.h3,{id:"1-2d-lidar-configuration",children:"1. 2D LiDAR Configuration"}),"\n",(0,s.jsx)(n.p,{children:"Setting up a 2D LiDAR for navigation and obstacle detection:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-xml",children:'<sensor name="laser_2d" type="ray">\n  <pose>0 0 0.8 0 0 0</pose> \x3c!-- On robot\'s torso --\x3e\n  <ray>\n    <scan>\n      <horizontal>\n        <samples>720</samples>\n        <resolution>1</resolution>\n        <min_angle>-1.5708</min_angle> \x3c!-- -90 degrees --\x3e\n        <max_angle>1.5708</max_angle>   \x3c!-- 90 degrees --\x3e\n      </horizontal>\n    </scan>\n    <range>\n      <min>0.1</min>\n      <max>10.0</max>\n      <resolution>0.01</resolution>\n    </range>\n  </ray>\n\n  <plugin name="laser_2d_controller" filename="libgazebo_ros_ray_sensor.so">\n    <ros>\n      <namespace>/laser_2d</namespace>\n      <remapping>~/out:=scan</remapping>\n    </ros>\n    <output_type>sensor_msgs/LaserScan</output_type>\n    <frame_name>laser_2d_frame</frame_name>\n  </plugin>\n</sensor>\n'})}),"\n",(0,s.jsx)(n.h3,{id:"2-3d-lidar-configuration",children:"2. 3D LiDAR Configuration"}),"\n",(0,s.jsx)(n.p,{children:"For comprehensive 3D environment mapping:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-xml",children:'<sensor name="velodyne_vlp16" type="ray">\n  <pose>0 0 1.2 0 0 0</pose> \x3c!-- On robot\'s head --\x3e\n  <ray>\n    <scan>\n      <horizontal>\n        <samples>1800</samples>\n        <resolution>1</resolution>\n        <min_angle>-3.14159</min_angle> \x3c!-- -180 degrees --\x3e\n        <max_angle>3.14159</max_angle>   \x3c!-- 180 degrees --\x3e\n      </horizontal>\n      <vertical>\n        <samples>16</samples>\n        <resolution>1</resolution>\n        <min_angle>-0.2618</min_angle> \x3c!-- -15 degrees --\x3e\n        <max_angle>0.2618</max_angle>   \x3c!-- 15 degrees --\x3e\n      </vertical>\n    </scan>\n    <range>\n      <min>0.2</min>\n      <max>100.0</max>\n      <resolution>0.001</resolution>\n    </range>\n  </ray>\n\n  <plugin name="velodyne_vlp16_controller" filename="libgazebo_ros_velodyne_laserscan.so">\n    <ros>\n      <namespace>/velodyne</namespace>\n      <remapping>~/out:=/velodyne_points</remapping>\n    </ros>\n    <topic_name>/velodyne_points</topic_name>\n    <frame_name>velodyne_frame</frame_name>\n    <min_range>0.2</min_range>\n    <max_range>100.0</max_range>\n    <gaussian_noise>0.008</gaussian_noise>\n  </plugin>\n</sensor>\n'})}),"\n",(0,s.jsx)(n.h3,{id:"3-multi-beam-lidar",children:"3. Multi-Beam LiDAR"}),"\n",(0,s.jsx)(n.p,{children:"For humanoid robots requiring detailed environment perception:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-xml",children:'<sensor name="multi_beam_lidar" type="ray">\n  <pose>0.1 0 0.9 0 0 0</pose> \x3c!-- On robot\'s chest --\x3e\n  <ray>\n    <scan>\n      <horizontal>\n        <samples>360</samples>\n        <resolution>1</resolution>\n        <min_angle>-3.14159</min_angle> \x3c!-- -180 degrees --\x3e\n        <max_angle>3.14159</max_angle>   \x3c!-- 180 degrees --\x3e\n      </horizontal>\n      <vertical>\n        <samples>32</samples>\n        <resolution>1</resolution>\n        <min_angle>-0.5236</min_angle> \x3c!-- -30 degrees --\x3e\n        <max_angle>0.5236</max_angle>   \x3c!-- 30 degrees --\x3e\n      </vertical>\n    </scan>\n    <range>\n      <min>0.1</min>\n      <max>50.0</max>\n      <resolution>0.001</resolution>\n    </range>\n  </ray>\n\n  <plugin name="multi_beam_controller" filename="libgazebo_ros_laser.so">\n    <topic_name>/multi_beam_scan</topic_name>\n    <frame_name>multi_beam_frame</frame_name>\n    <min_range>0.1</min_range>\n    <max_range>50.0</max_range>\n    <update_rate>10</update_rate>\n    <gaussian_noise>0.01</gaussian_noise>\n  </plugin>\n</sensor>\n'})}),"\n",(0,s.jsx)(n.h2,{id:"imu-sensor-simulation",children:"IMU Sensor Simulation"}),"\n",(0,s.jsx)(n.h3,{id:"1-basic-imu-configuration",children:"1. Basic IMU Configuration"}),"\n",(0,s.jsx)(n.p,{children:"Setting up an IMU sensor for orientation and acceleration data:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-xml",children:'<sensor name="imu_sensor" type="imu">\n  <pose>0 0 0 0 0 0</pose> \x3c!-- At robot\'s center of mass --\x3e\n  <imu>\n    \x3c!-- Noise parameters for realistic simulation --\x3e\n    <angular_velocity>\n      <x>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.01</stddev>\n        </noise>\n      </x>\n      <y>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.01</stddev>\n        </noise>\n      </y>\n      <z>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.01</stddev>\n        </noise>\n      </z>\n    </angular_velocity>\n\n    <linear_acceleration>\n      <x>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.017</stddev>\n        </noise>\n      </x>\n      <y>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.017</stddev>\n        </noise>\n      </y>\n      <z>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.017</stddev>\n        </noise>\n      </z>\n    </linear_acceleration>\n  </imu>\n\n  <plugin name="imu_controller" filename="libgazebo_ros_imu.so">\n    <ros>\n      <namespace>/imu</namespace>\n      <remapping>~/out:=data</remapping>\n    </ros>\n    <topic_name>/imu/data</topic_name>\n    <frame_name>imu_frame</frame_name>\n    <body_name>base_link</body_name>\n    <update_rate>100</update_rate>\n    <gaussian_noise>0.01</gaussian_noise>\n  </plugin>\n</sensor>\n'})}),"\n",(0,s.jsx)(n.h3,{id:"2-advanced-imu-with-magnetometer",children:"2. Advanced IMU with Magnetometer"}),"\n",(0,s.jsx)(n.p,{children:"For complete orientation estimation:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-xml",children:'<sensor name="imu_sensor_advanced" type="imu">\n  <pose>0 0 0.1 0 0 0</pose> \x3c!-- Slightly above center --\x3e\n  <imu>\n    \x3c!-- Angular velocity with bias --\x3e\n    <angular_velocity>\n      <x>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.01</stddev>\n          <bias_mean>0.0</bias_mean>\n          <bias_stddev>0.001</bias_stddev>\n        </noise>\n      </x>\n      <y>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.01</stddev>\n          <bias_mean>0.0</bias_mean>\n          <bias_stddev>0.001</bias_stddev>\n        </noise>\n      </y>\n      <z>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.01</stddev>\n          <bias_mean>0.0</bias_mean>\n          <bias_stddev>0.001</bias_stddev>\n        </noise>\n      </z>\n    </angular_velocity>\n\n    \x3c!-- Linear acceleration with bias --\x3e\n    <linear_acceleration>\n      <x>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.017</stddev>\n          <bias_mean>0.0</bias_mean>\n          <bias_stddev>0.001</bias_stddev>\n        </noise>\n      </x>\n      <y>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.017</stddev>\n          <bias_mean>0.0</bias_mean>\n          <bias_stddev>0.001</bias_stddev>\n        </noise>\n      </y>\n      <z>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.017</stddev>\n          <bias_mean>0.0</bias_mean>\n          <bias_stddev>0.001</bias_stddev>\n        </noise>\n      </z>\n    </linear_acceleration>\n\n    \x3c!-- Magnetometer simulation --\x3e\n    <magnetic_field>\n      <x>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>5e-06</stddev>\n        </noise>\n      </x>\n      <y>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>5e-06</stddev>\n        </noise>\n      </y>\n      <z>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>5e-06</stddev>\n        </noise>\n      </z>\n    </magnetic_field>\n  </imu>\n\n  <plugin name="advanced_imu_controller" filename="libgazebo_ros_imu.so">\n    <ros>\n      <namespace>/imu</namespace>\n      <remapping>~/out:=data</remapping>\n      <remapping>~/magnetic_field:=magnetic_field</remapping>\n    </ros>\n    <topic_name>/imu/data</topic_name>\n    <magnetic_field_topic_name>/imu/magnetic_field</topic_name>\n    <frame_name>imu_advanced_frame</frame_name>\n    <body_name>base_link</body_name>\n    <update_rate>100</update_rate>\n  </plugin>\n</sensor>\n'})}),"\n",(0,s.jsx)(n.h2,{id:"forcetorque-sensor-simulation",children:"Force/Torque Sensor Simulation"}),"\n",(0,s.jsx)(n.h3,{id:"1-joint-forcetorque-sensors",children:"1. Joint Force/Torque Sensors"}),"\n",(0,s.jsx)(n.p,{children:"Simulating force and torque measurements at joints:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-xml",children:'<sensor name="ft_sensor_left_foot" type="force_torque">\n  <pose>0 0 0 0 0 0</pose>\n  <force_torque>\n    <frame>child</frame> \x3c!-- Measures in child link frame --\x3e\n    <measure_direction>child_to_parent</measure_direction>\n  </force_torque>\n\n  <plugin name="ft_left_foot_controller" filename="libgazebo_ros_ft_sensor.so">\n    <ros>\n      <namespace>/ft_sensors</namespace>\n      <remapping>~/wrench:=left_foot_wrench</remapping>\n    </ros>\n    <topic_name>/ft_sensors/left_foot</topic_name>\n    <frame_name>left_foot_frame</frame_name>\n    <body_name>left_foot_link</body_name>\n  </plugin>\n</sensor>\n\n<sensor name="ft_sensor_right_foot" type="force_torque">\n  <pose>0 0 0 0 0 0</pose>\n  <force_torque>\n    <frame>child</frame>\n    <measure_direction>child_to_parent</measure_direction>\n  </force_torque>\n\n  <plugin name="ft_right_foot_controller" filename="libgazebo_ros_ft_sensor.so">\n    <ros>\n      <namespace>/ft_sensors</namespace>\n      <remapping>~/wrench:=right_foot_wrench</remapping>\n    </ros>\n    <topic_name>/ft_sensors/right_foot</topic_name>\n    <frame_name>right_foot_frame</frame_name>\n    <body_name>right_foot_link</body_name>\n  </plugin>\n</sensor>\n'})}),"\n",(0,s.jsx)(n.h3,{id:"2-six-axis-forcetorque-sensor",children:"2. Six-Axis Force/Torque Sensor"}),"\n",(0,s.jsx)(n.p,{children:"For comprehensive contact force analysis:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-xml",children:'<sensor name="six_axis_ft_sensor" type="force_torque">\n  <pose>0 0 0 0 0 0</pose>\n  <force_torque>\n    <frame>sensor</frame>\n    <measure_direction>sensor_to_world</measure_direction>\n\n    \x3c!-- Noise parameters --\x3e\n    <force>\n      <x>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.1</stddev>\n        </noise>\n      </x>\n      <y>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.1</stddev>\n        </noise>\n      </y>\n      <z>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.1</stddev>\n        </noise>\n      </z>\n    </force>\n\n    <torque>\n      <x>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.01</stddev>\n        </noise>\n      </x>\n      <y>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.01</stddev>\n        </noise>\n      </y>\n      <z>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.01</stddev>\n        </noise>\n      </z>\n    </torque>\n  </force_torque>\n\n  <plugin name="six_axis_ft_controller" filename="libgazebo_ros_ft_sensor.so">\n    <ros>\n      <namespace>/ft_sensors</namespace>\n      <remapping>~/wrench:=wrench</remapping>\n    </ros>\n    <topic_name>/ft_sensors/six_axis</topic_name>\n    <frame_name>six_axis_ft_frame</frame_name>\n    <body_name>sensor_body</body_name>\n    <update_rate>100</update_rate>\n  </plugin>\n</sensor>\n'})}),"\n",(0,s.jsx)(n.h2,{id:"gps-sensor-simulation",children:"GPS Sensor Simulation"}),"\n",(0,s.jsx)(n.h3,{id:"1-gps-configuration-for-outdoor-navigation",children:"1. GPS Configuration for Outdoor Navigation"}),"\n",(0,s.jsx)(n.p,{children:"For humanoid robots operating in outdoor environments:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-xml",children:'<sensor name="gps_sensor" type="gps">\n  <pose>0 0 1.5 0 0 0</pose> \x3c!-- On robot\'s head --\x3e\n  <gps>\n    <position_sensing>\n      <horizontal>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.2</stddev>\n        </noise>\n      </horizontal>\n      <vertical>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.3</stddev>\n        </noise>\n      </vertical>\n    </position_sensing>\n\n    <velocity_sensing>\n      <horizontal>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.1</stddev>\n        </noise>\n      </horizontal>\n      <vertical>\n        <noise type="gaussian">\n          <mean>0.0</mean>\n          <stddev>0.1</stddev>\n        </noise>\n      </vertical>\n    </velocity_sensing>\n  </gps>\n\n  <plugin name="gps_controller" filename="libgazebo_ros_gps.so">\n    <ros>\n      <namespace>/gps</namespace>\n      <remapping>~/out:=fix</remapping>\n    </ros>\n    <topic_name>/gps/fix</topic_name>\n    <frame_name>gps_frame</frame_name>\n    <update_rate>10</update_rate>\n  </plugin>\n</sensor>\n'})}),"\n",(0,s.jsx)(n.h2,{id:"sensor-fusion-and-data-processing",children:"Sensor Fusion and Data Processing"}),"\n",(0,s.jsx)(n.h3,{id:"1-robot-state-publisher-integration",children:"1. Robot State Publisher Integration"}),"\n",(0,s.jsx)(n.p,{children:"Integrating sensor data with robot state information:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-xml",children:'\x3c!-- In your launch file or robot description --\x3e\n<node pkg="robot_state_publisher" exec="robot_state_publisher" name="robot_state_publisher">\n  <param name="publish_frequency" value="50.0"/>\n  <param name="use_tf_static" value="true"/>\n  <param name="ignore_timestamp" value="false"/>\n</node>\n\n\x3c!-- Joint state publisher --\x3e\n<node pkg="joint_state_publisher" exec="joint_state_publisher" name="joint_state_publisher">\n  <param name="rate" value="50"/>\n  <param name="use_gui" value="false"/>\n</node>\n'})}),"\n",(0,s.jsx)(n.h3,{id:"2-sensor-data-aggregation",children:"2. Sensor Data Aggregation"}),"\n",(0,s.jsx)(n.p,{children:"Creating a comprehensive sensor data system:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-xml",children:'\x3c!-- Example of a complex humanoid robot with multiple sensors --\x3e\n<sdf version="1.7">\n  <model name="humanoid_robot_with_sensors">\n    <link name="base_link">\n      <inertial>\n        <mass>75.0</mass>\n        <origin xyz="0 0 0" rpy="0 0 0"/>\n        <inertia ixx="5.0" ixy="0.0" ixz="0.0" iyy="5.0" iyz="0.0" izz="5.0"/>\n      </inertial>\n\n      \x3c!-- Main IMU on torso --\x3e\n      <sensor name="torso_imu" type="imu">\n        <pose>0 0 0.1 0 0 0</pose>\n        <imu>\n          <angular_velocity>\n            <x><noise type="gaussian"><stddev>0.01</stddev></noise></x>\n            <y><noise type="gaussian"><stddev>0.01</stddev></noise></y>\n            <z><noise type="gaussian"><stddev>0.01</stddev></noise></z>\n          </angular_velocity>\n          <linear_acceleration>\n            <x><noise type="gaussian"><stddev>0.017</stddev></noise></x>\n            <y><noise type="gaussian"><stddev>0.017</stddev></noise></y>\n            <z><noise type="gaussian"><stddev>0.017</stddev></noise></z>\n          </linear_acceleration>\n        </imu>\n        <plugin name="torso_imu_controller" filename="libgazebo_ros_imu.so">\n          <topic_name>/imu/data</topic_name>\n          <frame_name>torso_imu_frame</frame_name>\n          <body_name>base_link</body_name>\n          <update_rate>100</update_rate>\n        </plugin>\n      </sensor>\n    </link>\n\n    <link name="head_link">\n      <pose>0 0 0.2 0 0 0</pose>\n\n      \x3c!-- Head camera --\x3e\n      <sensor name="head_camera" type="camera">\n        <pose>0.05 0 0 0 0 0</pose>\n        <camera name="rgb_camera">\n          <image><width>640</width><height>480</height><format>R8G8B8</format></image>\n          <horizontal_fov>1.0472</horizontal_fov>\n          <clip><near>0.1</near><far>10.0</far></clip>\n        </camera>\n        <plugin name="head_camera_controller" filename="libgazebo_ros_camera.so">\n          <topic_name>/head_camera/image_raw</topic_name>\n          <camera_info_topic_name>/head_camera/camera_info</camera_info_topic_name>\n          <frame_name>head_camera_frame</frame_name>\n        </plugin>\n      </sensor>\n\n      \x3c!-- Head LiDAR --\x3e\n      <sensor name="head_lidar" type="ray">\n        <pose>0 0 0.05 0 0 0</pose>\n        <ray>\n          <scan><horizontal><samples>360</samples><min_angle>-3.14159</min_angle><max_angle>3.14159</max_angle></horizontal></scan>\n          <range><min>0.1</min><max>10.0</max></range>\n        </ray>\n        <plugin name="head_lidar_controller" filename="libgazebo_ros_laser.so">\n          <topic_name>/head_lidar/scan</topic_name>\n          <frame_name>head_lidar_frame</frame_name>\n          <update_rate>10</update_rate>\n        </plugin>\n      </sensor>\n    </link>\n\n    \x3c!-- Joint sensors for feet --\x3e\n    <joint name="left_foot_joint" type="fixed">\n      <parent>base_link</parent>\n      <child>left_foot_link</child>\n      <sensor name="left_foot_ft" type="force_torque">\n        <pose>0 0 -0.05 0 0 0</pose>\n        <force_torque><frame>child</frame><measure_direction>child_to_parent</measure_direction></force_torque>\n        <plugin name="left_foot_ft_controller" filename="libgazebo_ros_ft_sensor.so">\n          <topic_name>/ft_sensors/left_foot</topic_name>\n          <frame_name>left_foot_frame</frame_name>\n        </plugin>\n      </sensor>\n    </joint>\n\n    <link name="left_foot_link">\n      <pose>-0.1 -0.1 -0.05 0 0 0</pose>\n      <collision name="collision">\n        <geometry><box><size>0.2 0.1 0.05</size></box></geometry>\n      </collision>\n      <visual name="visual">\n        <geometry><box><size>0.2 0.1 0.05</size></box></geometry>\n      </visual>\n    </link>\n  </model>\n</sdf>\n'})}),"\n",(0,s.jsx)(n.h2,{id:"sensor-performance-optimization",children:"Sensor Performance Optimization"}),"\n",(0,s.jsx)(n.h3,{id:"1-efficient-sensor-configuration",children:"1. Efficient Sensor Configuration"}),"\n",(0,s.jsx)(n.p,{children:"Optimizing sensor performance for real-time simulation:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-xml",children:'\x3c!-- Optimized camera settings for real-time performance --\x3e\n<sensor name="optimized_camera" type="camera">\n  <camera name="real_time_camera">\n    <image>\n      <width>320</width>    \x3c!-- Lower resolution for performance --\x3e\n      <height>240</height>\n      <format>R8G8B8</format>\n    </image>\n    <horizontal_fov>1.0472</horizontal_fov>\n    <clip><near>0.1</near><far>5.0</far></clip>\n  </camera>\n  <update_rate>30</update_rate> \x3c!-- Lower update rate for performance --\x3e\n  <plugin name="optimized_camera_controller" filename="libgazebo_ros_camera.so">\n    <topic_name>/camera/image_raw</topic_name>\n    <update_rate>30</update_rate> \x3c!-- Match sensor update rate --\x3e\n  </plugin>\n</sensor>\n\n\x3c!-- Optimized LiDAR for real-time navigation --\x3e\n<sensor name="optimized_lidar" type="ray">\n  <ray>\n    <scan>\n      <horizontal>\n        <samples>360</samples> \x3c!-- Reduced samples for performance --\x3e\n        <min_angle>-3.14159</min_angle>\n        <max_angle>3.14159</max_angle>\n      </horizontal>\n    </scan>\n    <range><min>0.1</min><max>5.0</max></range>\n  </ray>\n  <update_rate>10</update_rate> \x3c!-- Lower update rate --\x3e\n  <plugin name="optimized_lidar_controller" filename="libgazebo_ros_laser.so">\n    <update_rate>10</update_rate>\n  </plugin>\n</sensor>\n'})}),"\n",(0,s.jsx)(n.h3,{id:"2-sensor-scheduling-and-threading",children:"2. Sensor Scheduling and Threading"}),"\n",(0,s.jsx)(n.p,{children:"Configuring sensor updates for optimal performance:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-xml",children:'\x3c!-- In your world file or launch configuration --\x3e\n<world name="humanoid_sensor_world">\n  \x3c!-- Physics settings optimized for sensor performance --\x3e\n  <physics type="ode">\n    <max_step_size>0.001</max_step_size>\n    <real_time_factor>1.0</real_time_factor>\n    <real_time_update_rate>1000.0</real_time_update_rate>\n    <ode>\n      <solver><type>quick</type></solver>\n      <constraints><cfm>0.000001</cfm><erp>0.2</erp></constraints>\n    </ode>\n  </physics>\n\n  \x3c!-- Your robot and sensors go here --\x3e\n  \x3c!-- ... --\x3e\n</world>\n'})}),"\n",(0,s.jsx)(n.h2,{id:"sensor-validation-and-testing",children:"Sensor Validation and Testing"}),"\n",(0,s.jsx)(n.h3,{id:"1-sensor-data-validation",children:"1. Sensor Data Validation"}),"\n",(0,s.jsx)(n.p,{children:"Creating validation scripts to ensure sensor accuracy:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\n# sensor_validation.py\n\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image, LaserScan, Imu, JointState\nfrom geometry_msgs.msg import PointStamped\nimport numpy as np\n\nclass SensorValidationNode(Node):\n    def __init__(self):\n        super().__init__('sensor_validation_node')\n\n        # Subscribe to various sensor topics\n        self.camera_sub = self.create_subscription(\n            Image, '/camera/image_raw', self.camera_callback, 10)\n        self.lidar_sub = self.create_subscription(\n            LaserScan, '/scan', self.lidar_callback, 10)\n        self.imu_sub = self.create_subscription(\n            Imu, '/imu/data', self.imu_callback, 10)\n        self.joint_sub = self.create_subscription(\n            JointState, '/joint_states', self.joint_callback, 10)\n\n        # Timer for periodic validation\n        self.timer = self.create_timer(1.0, self.periodic_validation)\n\n        self.camera_data_received = False\n        self.lidar_data_received = False\n        self.imu_data_received = False\n        self.joint_data_received = False\n\n        self.get_logger().info('Sensor validation node initialized')\n\n    def camera_callback(self, msg):\n        # Validate camera data\n        expected_size = msg.width * msg.height * 3  # RGB\n        if len(msg.data) == expected_size:\n            self.camera_data_received = True\n            self.get_logger().debug(f'Valid camera data: {msg.width}x{msg.height}')\n        else:\n            self.get_logger().warn(f'Invalid camera data size: expected {expected_size}, got {len(msg.data)}')\n\n    def lidar_callback(self, msg):\n        # Validate LiDAR data\n        expected_samples = int((msg.angle_max - msg.angle_min) / msg.angle_increment) + 1\n        if len(msg.ranges) == expected_samples:\n            self.lidar_data_received = True\n            valid_ranges = [r for r in msg.ranges if msg.range_min <= r <= msg.range_max]\n            self.get_logger().debug(f'Valid LiDAR data: {len(valid_ranges)}/{len(msg.ranges)} valid ranges')\n        else:\n            self.get_logger().warn(f'Invalid LiDAR data: expected {expected_samples}, got {len(msg.ranges)}')\n\n    def imu_callback(self, msg):\n        # Validate IMU data\n        orientation_valid = abs(msg.orientation.x**2 + msg.orientation.y**2 +\n                               msg.orientation.z**2 + msg.orientation.w**2 - 1) < 0.01\n        if orientation_valid:\n            self.imu_data_received = True\n            self.get_logger().debug('Valid IMU orientation data')\n        else:\n            self.get_logger().warn('Invalid IMU orientation data')\n\n    def joint_callback(self, msg):\n        # Validate joint data\n        if len(msg.position) == len(msg.name):\n            self.joint_data_received = True\n            self.get_logger().debug(f'Valid joint data: {len(msg.position)} joints')\n        else:\n            self.get_logger().warn('Joint data mismatch: position and name arrays differ in length')\n\n    def periodic_validation(self):\n        sensors_status = {\n            'camera': self.camera_data_received,\n            'lidar': self.lidar_data_received,\n            'imu': self.imu_data_received,\n            'joints': self.joint_data_received\n        }\n\n        all_working = all(sensors_status.values())\n\n        if all_working:\n            self.get_logger().info('All sensors working correctly')\n        else:\n            for sensor, working in sensors_status.items():\n                status = 'OK' if working else 'ISSUE'\n                self.get_logger().info(f'{sensor}: {status}')\n\n        # Reset flags for next validation cycle\n        self.camera_data_received = False\n        self.lidar_data_received = False\n        self.imu_data_received = False\n        self.joint_data_received = False\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = SensorValidationNode()\n\n    try:\n        rclpy.spin(node)\n    except KeyboardInterrupt:\n        node.get_logger().info('Sensor validation node shutting down')\n    finally:\n        node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,s.jsx)(n.h2,{id:"troubleshooting-common-sensor-issues",children:"Troubleshooting Common Sensor Issues"}),"\n",(0,s.jsx)(n.h3,{id:"1-sensor-data-quality-issues",children:"1. Sensor Data Quality Issues"}),"\n",(0,s.jsx)(n.p,{children:"Common problems and solutions:"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Problem: No sensor data being published"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Check if the sensor plugin is correctly loaded"}),"\n",(0,s.jsx)(n.li,{children:"Verify topic names and namespaces"}),"\n",(0,s.jsx)(n.li,{children:"Ensure the robot model is properly loaded"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Problem: Low-quality sensor data"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Adjust noise parameters in the sensor configuration"}),"\n",(0,s.jsx)(n.li,{children:"Verify physics parameters for realistic simulation"}),"\n",(0,s.jsx)(n.li,{children:"Check update rates and performance settings"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Problem: Inconsistent sensor readings"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Ensure proper frame transformations"}),"\n",(0,s.jsx)(n.li,{children:"Check for timing issues between sensors"}),"\n",(0,s.jsx)(n.li,{children:"Verify coordinate system conventions"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"2-performance-issues",children:"2. Performance Issues"}),"\n",(0,s.jsx)(n.p,{children:"Optimizing sensor performance:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Reduce sensor update rates for less critical sensors"}),"\n",(0,s.jsx)(n.li,{children:"Lower resolution for cameras when possible"}),"\n",(0,s.jsx)(n.li,{children:"Reduce LiDAR sample counts for real-time applications"}),"\n",(0,s.jsx)(n.li,{children:"Use appropriate collision geometries (simpler than visual)"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsx)(n.p,{children:"With comprehensive sensor simulation implemented in Gazebo, you now have a complete digital twin system with realistic perception capabilities. The sensors provide the data needed for humanoid robot navigation, control, and interaction with the environment."}),"\n",(0,s.jsx)(n.p,{children:"In the next section, we'll explore how to integrate these Gazebo sensors with ROS 2 perception pipelines and create complete perception systems for your humanoid robots."})]})}function c(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,n,a)=>{a.d(n,{R:()=>r,x:()=>t});var i=a(6540);const s={},o=i.createContext(s);function r(e){const n=i.useContext(o);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function t(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),i.createElement(o.Provider,{value:n},e.children)}}}]);